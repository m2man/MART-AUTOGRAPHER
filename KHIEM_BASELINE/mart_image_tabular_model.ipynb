{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_FNPV50fX-B"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wquACijMfX-E"
   },
   "source": [
    "# Initial Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wOipfXEfX-F"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/sda/hong01-data/MART_DATA/OUTPUT_MERGED'\n",
    "CSV_DIR = osp.join(DATA_DIR, 'PANDAS')\n",
    "IMG_DIR = osp.join(DATA_DIR, 'AUTOGRAPHER')\n",
    "SCREENSHOT_DIR = osp.join(DATA_DIR, 'SCREENSHOTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvCz3UEQfX-I"
   },
   "outputs": [],
   "source": [
    "events_text = {'act00': 'calibration',\n",
    "                'act01': 'write an email',\n",
    "                'act02': 'read on screen',\n",
    "                'act03': 'edit/create presentation',\n",
    "                'act04': 'zone out and fixate',\n",
    "                'act05': 'use a calculator to add up numbers on sheet',\n",
    "                'act06': 'physical precision task',\n",
    "                'act07': 'put documents in order',\n",
    "                'act08': 'read text/numbers on page',\n",
    "                'act09': 'arrange money in change jar',\n",
    "                'act10': 'write on paper with pen',\n",
    "                'act11': 'watch a youtube video',\n",
    "                'act12': 'go to a news website and browse',\n",
    "                'act13': 'have conversation with experimenter in room',\n",
    "                'act14': 'make a telephone call',\n",
    "                'act15': 'drink/eat for 2 minutes',\n",
    "                'act16': 'close eyes and sit still',\n",
    "                'act17': 'clean e.g. sweaping the floor, wipe, ...',\n",
    "                'act18': 'exercise: sit up/stand down repeatedly',\n",
    "                'act19': 'hand-eye coordination (tennis ball)',\n",
    "                'act20': 'pace the room',\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlAP1aKSJRC_"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3BafoPxfX-L"
   },
   "outputs": [],
   "source": [
    "dfA = pd.read_csv(osp.join(CSV_DIR, 'trainA.csv'), index_col=0)\n",
    "dfB = pd.read_csv(osp.join(CSV_DIR, 'trainB.csv'), index_col=0)\n",
    "df = pd.concat([dfA, dfB])\n",
    "df = df.sort_values(by=['event_id', 'sub_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "MYEZK-pLfX-N",
    "outputId": "a406e06b-e0f5-4098-8650-c273180d9619"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>source</th>\n",
       "      <th>data_HR_activity_median</th>\n",
       "      <th>data_HR_activity_min</th>\n",
       "      <th>data_HR_activity_max</th>\n",
       "      <th>data_HR_activity_average</th>\n",
       "      <th>data_HR_activity_std</th>\n",
       "      <th>data_HR_activity_len</th>\n",
       "      <th>data_LEFT_ACC_MAG_median</th>\n",
       "      <th>...</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_buckeye, horse chestnut, conker</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_coral fungus</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_agaric</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_gyromitra</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_stinkhorn, carrion fungus</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_earthstar</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_bolete</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_ear, spike, capitulum</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_toilet tissue, toilet paper, bathroom tissue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.577495</td>\n",
       "      <td>3.933112</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainB</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>81.081081</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>86.525331</td>\n",
       "      <td>2.709545</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.009232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>68.181818</td>\n",
       "      <td>60.606061</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>67.920213</td>\n",
       "      <td>3.254272</td>\n",
       "      <td>90</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainB</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>67.415730</td>\n",
       "      <td>77.922078</td>\n",
       "      <td>71.630717</td>\n",
       "      <td>2.240689</td>\n",
       "      <td>90</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.005427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>74.074074</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>73.875941</td>\n",
       "      <td>2.166754</td>\n",
       "      <td>90</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.066273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1005</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>98.360656</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>105.263158</td>\n",
       "      <td>98.556521</td>\n",
       "      <td>3.391250</td>\n",
       "      <td>89</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.750323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1006</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainA</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91.705138</td>\n",
       "      <td>2.563889</td>\n",
       "      <td>90</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.422092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1006</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>103.448276</td>\n",
       "      <td>94.153427</td>\n",
       "      <td>4.012861</td>\n",
       "      <td>89</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.296006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainA</td>\n",
       "      <td>89.552239</td>\n",
       "      <td>74.074074</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>87.873433</td>\n",
       "      <td>4.945947</td>\n",
       "      <td>89</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.010341</td>\n",
       "      <td>0.711271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>91.244665</td>\n",
       "      <td>2.822364</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 3111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_id event_id  source  data_HR_activity_median  data_HR_activity_min  \\\n",
       "0     1001    act01  trainA                84.507042             76.923077   \n",
       "0     1001    act01  trainB                85.714286             81.081081   \n",
       "0     1002    act01  trainA                68.181818             60.606061   \n",
       "0     1002    act01  trainB                71.428571             67.415730   \n",
       "0     1003    act01  trainA                74.074074             66.666667   \n",
       "..     ...      ...     ...                      ...                   ...   \n",
       "19    1005    act20  trainB                98.360656             84.507042   \n",
       "19    1006    act20  trainA                92.307692             85.714286   \n",
       "19    1006    act20  trainB                93.750000             84.507042   \n",
       "19    1007    act20  trainA                89.552239             74.074074   \n",
       "19    1007    act20  trainB                90.909091             85.714286   \n",
       "\n",
       "    data_HR_activity_max  data_HR_activity_average  data_HR_activity_std  \\\n",
       "0             100.000000                 84.577495              3.933112   \n",
       "0              92.307692                 86.525331              2.709545   \n",
       "0              75.000000                 67.920213              3.254272   \n",
       "0              77.922078                 71.630717              2.240689   \n",
       "0              78.947368                 73.875941              2.166754   \n",
       "..                   ...                       ...                   ...   \n",
       "19            105.263158                 98.556521              3.391250   \n",
       "19            100.000000                 91.705138              2.563889   \n",
       "19            103.448276                 94.153427              4.012861   \n",
       "19             96.774194                 87.873433              4.945947   \n",
       "19             96.774194                 91.244665              2.822364   \n",
       "\n",
       "    data_HR_activity_len  data_LEFT_ACC_MAG_median  ...  \\\n",
       "0                     90                  0.000500  ...   \n",
       "0                     90                  0.000850  ...   \n",
       "0                     90                 -0.002704  ...   \n",
       "0                     90                 -0.003506  ...   \n",
       "0                     90                  0.021029  ...   \n",
       "..                   ...                       ...  ...   \n",
       "19                    89                  0.006852  ...   \n",
       "19                    90                  0.003494  ...   \n",
       "19                    89                  0.005112  ...   \n",
       "19                    89                  0.021470  ...   \n",
       "19                    89                  0.025573  ...   \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_buckeye, horse chestnut, conker  \\\n",
       "0                                            0.000728             \n",
       "0                                            0.001672             \n",
       "0                                            0.000050             \n",
       "0                                            0.001901             \n",
       "0                                            0.006064             \n",
       "..                                                ...             \n",
       "19                                           0.002078             \n",
       "19                                           0.001213             \n",
       "19                                           0.001420             \n",
       "19                                           0.000450             \n",
       "19                                           0.000404             \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_coral fungus  \\\n",
       "0                                   0.000090   \n",
       "0                                   0.000244   \n",
       "0                                   0.000004   \n",
       "0                                   0.000151   \n",
       "0                                   0.000295   \n",
       "..                                       ...   \n",
       "19                                  0.000269   \n",
       "19                                  0.001381   \n",
       "19                                  0.001601   \n",
       "19                                  0.003216   \n",
       "19                                  0.004949   \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_agaric  data_AUTOGRAPHER_RESNET_max_gyromitra  \\\n",
       "0                             0.000920                               0.000048   \n",
       "0                             0.003576                               0.000128   \n",
       "0                             0.000071                               0.000002   \n",
       "0                             0.000966                               0.000082   \n",
       "0                             0.007819                               0.000449   \n",
       "..                                 ...                                    ...   \n",
       "19                            0.000881                               0.000034   \n",
       "19                            0.001589                               0.000075   \n",
       "19                            0.001030                               0.000053   \n",
       "19                            0.001190                               0.000040   \n",
       "19                            0.003061                               0.000078   \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_stinkhorn, carrion fungus  \\\n",
       "0                                            0.000100       \n",
       "0                                            0.000239       \n",
       "0                                            0.000003       \n",
       "0                                            0.000151       \n",
       "0                                            0.000692       \n",
       "..                                                ...       \n",
       "19                                           0.000167       \n",
       "19                                           0.000245       \n",
       "19                                           0.000363       \n",
       "19                                           0.000681       \n",
       "19                                           0.002761       \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_earthstar  \\\n",
       "0                                0.000287   \n",
       "0                                0.000618   \n",
       "0                                0.000009   \n",
       "0                                0.000299   \n",
       "0                                0.003246   \n",
       "..                                    ...   \n",
       "19                               0.000108   \n",
       "19                               0.000297   \n",
       "19                               0.000531   \n",
       "19                               0.000378   \n",
       "19                               0.000641   \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa  \\\n",
       "0                                            0.000317                                                       \n",
       "0                                            0.000757                                                       \n",
       "0                                            0.000100                                                       \n",
       "0                                            0.000926                                                       \n",
       "0                                            0.004795                                                       \n",
       "..                                                ...                                                       \n",
       "19                                           0.000597                                                       \n",
       "19                                           0.001900                                                       \n",
       "19                                           0.001294                                                       \n",
       "19                                           0.000685                                                       \n",
       "19                                           0.000591                                                       \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_bolete  \\\n",
       "0                             0.000290   \n",
       "0                             0.000928   \n",
       "0                             0.000031   \n",
       "0                             0.000762   \n",
       "0                             0.002219   \n",
       "..                                 ...   \n",
       "19                            0.000377   \n",
       "19                            0.000491   \n",
       "19                            0.000652   \n",
       "19                            0.000530   \n",
       "19                            0.001960   \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_ear, spike, capitulum  \\\n",
       "0                                            0.001594   \n",
       "0                                            0.005534   \n",
       "0                                            0.000402   \n",
       "0                                            0.008168   \n",
       "0                                            0.007301   \n",
       "..                                                ...   \n",
       "19                                           0.001633   \n",
       "19                                           0.003848   \n",
       "19                                           0.005349   \n",
       "19                                           0.010341   \n",
       "19                                           0.004449   \n",
       "\n",
       "    data_AUTOGRAPHER_RESNET_max_toilet tissue, toilet paper, bathroom tissue  \n",
       "0                                            0.001767                         \n",
       "0                                            0.009232                         \n",
       "0                                            0.000734                         \n",
       "0                                            0.005427                         \n",
       "0                                            0.066273                         \n",
       "..                                                ...                         \n",
       "19                                           0.750323                         \n",
       "19                                           0.422092                         \n",
       "19                                           0.296006                         \n",
       "19                                           0.711271                         \n",
       "19                                           0.147818                         \n",
       "\n",
       "[280 rows x 3111 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jP0V-4RwxzDS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iampj11pgufb"
   },
   "outputs": [],
   "source": [
    "imgs = sorted(os.listdir(IMG_DIR))\n",
    "imgs = [item[:5]+'test_'+item[5:] if 'pred' in item else item for item in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odIQiBd6fX-S"
   },
   "outputs": [],
   "source": [
    "df_image = pd.DataFrame([item.split('_')+[item] for item in imgs], columns=['sub_id', 'source', 'event_id', 'img_order', 'image_path'])\n",
    "df_image = df_image.astype({'sub_id': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ID9W8wE-gxtc"
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(df, df_image, how='inner', on=['sub_id', 'event_id', 'source'])\n",
    "df_train['label'] = df_train.apply(lambda row: int(row['event_id'][-2:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "Zlzenbo6fX-V",
    "outputId": "1e35ef64-a30d-4728-9927-7f267bc433cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>source</th>\n",
       "      <th>data_HR_activity_median</th>\n",
       "      <th>data_HR_activity_min</th>\n",
       "      <th>data_HR_activity_max</th>\n",
       "      <th>data_HR_activity_average</th>\n",
       "      <th>data_HR_activity_std</th>\n",
       "      <th>data_HR_activity_len</th>\n",
       "      <th>data_LEFT_ACC_MAG_median</th>\n",
       "      <th>...</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_gyromitra</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_stinkhorn, carrion fungus</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_earthstar</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_bolete</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_ear, spike, capitulum</th>\n",
       "      <th>data_AUTOGRAPHER_RESNET_max_toilet tissue, toilet paper, bathroom tissue</th>\n",
       "      <th>img_order</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.577495</td>\n",
       "      <td>3.933112</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1001_trainA_act01_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.577495</td>\n",
       "      <td>3.933112</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1001_trainA_act01_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.577495</td>\n",
       "      <td>3.933112</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1001_trainA_act01_2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.577495</td>\n",
       "      <td>3.933112</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1001_trainA_act01_3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>act01</td>\n",
       "      <td>trainA</td>\n",
       "      <td>84.507042</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.577495</td>\n",
       "      <td>3.933112</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1001_trainA_act01_4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>91.244665</td>\n",
       "      <td>2.822364</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.147818</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1007_trainB_act20_0.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>91.244665</td>\n",
       "      <td>2.822364</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.147818</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1007_trainB_act20_1.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>91.244665</td>\n",
       "      <td>2.822364</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.147818</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1007_trainB_act20_2.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>91.244665</td>\n",
       "      <td>2.822364</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.147818</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1007_trainB_act20_3.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>1007</td>\n",
       "      <td>act20</td>\n",
       "      <td>trainB</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>91.244665</td>\n",
       "      <td>2.822364</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.147818</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1007_trainB_act20_4.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1830 rows × 3114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sub_id event_id  source  data_HR_activity_median  data_HR_activity_min  \\\n",
       "0       1001    act01  trainA                84.507042             76.923077   \n",
       "1       1001    act01  trainA                84.507042             76.923077   \n",
       "2       1001    act01  trainA                84.507042             76.923077   \n",
       "3       1001    act01  trainA                84.507042             76.923077   \n",
       "4       1001    act01  trainA                84.507042             76.923077   \n",
       "...      ...      ...     ...                      ...                   ...   \n",
       "1825    1007    act20  trainB                90.909091             85.714286   \n",
       "1826    1007    act20  trainB                90.909091             85.714286   \n",
       "1827    1007    act20  trainB                90.909091             85.714286   \n",
       "1828    1007    act20  trainB                90.909091             85.714286   \n",
       "1829    1007    act20  trainB                90.909091             85.714286   \n",
       "\n",
       "      data_HR_activity_max  data_HR_activity_average  data_HR_activity_std  \\\n",
       "0               100.000000                 84.577495              3.933112   \n",
       "1               100.000000                 84.577495              3.933112   \n",
       "2               100.000000                 84.577495              3.933112   \n",
       "3               100.000000                 84.577495              3.933112   \n",
       "4               100.000000                 84.577495              3.933112   \n",
       "...                    ...                       ...                   ...   \n",
       "1825             96.774194                 91.244665              2.822364   \n",
       "1826             96.774194                 91.244665              2.822364   \n",
       "1827             96.774194                 91.244665              2.822364   \n",
       "1828             96.774194                 91.244665              2.822364   \n",
       "1829             96.774194                 91.244665              2.822364   \n",
       "\n",
       "      data_HR_activity_len  data_LEFT_ACC_MAG_median  ...  \\\n",
       "0                       90                  0.000500  ...   \n",
       "1                       90                  0.000500  ...   \n",
       "2                       90                  0.000500  ...   \n",
       "3                       90                  0.000500  ...   \n",
       "4                       90                  0.000500  ...   \n",
       "...                    ...                       ...  ...   \n",
       "1825                    89                  0.025573  ...   \n",
       "1826                    89                  0.025573  ...   \n",
       "1827                    89                  0.025573  ...   \n",
       "1828                    89                  0.025573  ...   \n",
       "1829                    89                  0.025573  ...   \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_gyromitra  \\\n",
       "0                                  0.000048   \n",
       "1                                  0.000048   \n",
       "2                                  0.000048   \n",
       "3                                  0.000048   \n",
       "4                                  0.000048   \n",
       "...                                     ...   \n",
       "1825                               0.000078   \n",
       "1826                               0.000078   \n",
       "1827                               0.000078   \n",
       "1828                               0.000078   \n",
       "1829                               0.000078   \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_stinkhorn, carrion fungus  \\\n",
       "0                                              0.000100       \n",
       "1                                              0.000100       \n",
       "2                                              0.000100       \n",
       "3                                              0.000100       \n",
       "4                                              0.000100       \n",
       "...                                                 ...       \n",
       "1825                                           0.002761       \n",
       "1826                                           0.002761       \n",
       "1827                                           0.002761       \n",
       "1828                                           0.002761       \n",
       "1829                                           0.002761       \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_earthstar  \\\n",
       "0                                  0.000287   \n",
       "1                                  0.000287   \n",
       "2                                  0.000287   \n",
       "3                                  0.000287   \n",
       "4                                  0.000287   \n",
       "...                                     ...   \n",
       "1825                               0.000641   \n",
       "1826                               0.000641   \n",
       "1827                               0.000641   \n",
       "1828                               0.000641   \n",
       "1829                               0.000641   \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa  \\\n",
       "0                                              0.000317                                                       \n",
       "1                                              0.000317                                                       \n",
       "2                                              0.000317                                                       \n",
       "3                                              0.000317                                                       \n",
       "4                                              0.000317                                                       \n",
       "...                                                 ...                                                       \n",
       "1825                                           0.000591                                                       \n",
       "1826                                           0.000591                                                       \n",
       "1827                                           0.000591                                                       \n",
       "1828                                           0.000591                                                       \n",
       "1829                                           0.000591                                                       \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_bolete  \\\n",
       "0                                0.00029   \n",
       "1                                0.00029   \n",
       "2                                0.00029   \n",
       "3                                0.00029   \n",
       "4                                0.00029   \n",
       "...                                  ...   \n",
       "1825                             0.00196   \n",
       "1826                             0.00196   \n",
       "1827                             0.00196   \n",
       "1828                             0.00196   \n",
       "1829                             0.00196   \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_ear, spike, capitulum  \\\n",
       "0                                              0.001594   \n",
       "1                                              0.001594   \n",
       "2                                              0.001594   \n",
       "3                                              0.001594   \n",
       "4                                              0.001594   \n",
       "...                                                 ...   \n",
       "1825                                           0.004449   \n",
       "1826                                           0.004449   \n",
       "1827                                           0.004449   \n",
       "1828                                           0.004449   \n",
       "1829                                           0.004449   \n",
       "\n",
       "      data_AUTOGRAPHER_RESNET_max_toilet tissue, toilet paper, bathroom tissue  \\\n",
       "0                                              0.001767                          \n",
       "1                                              0.001767                          \n",
       "2                                              0.001767                          \n",
       "3                                              0.001767                          \n",
       "4                                              0.001767                          \n",
       "...                                                 ...                          \n",
       "1825                                           0.147818                          \n",
       "1826                                           0.147818                          \n",
       "1827                                           0.147818                          \n",
       "1828                                           0.147818                          \n",
       "1829                                           0.147818                          \n",
       "\n",
       "      img_order               image_path  label  \n",
       "0         0.jpg  1001_trainA_act01_0.jpg      1  \n",
       "1         1.jpg  1001_trainA_act01_1.jpg      1  \n",
       "2         2.jpg  1001_trainA_act01_2.jpg      1  \n",
       "3         3.jpg  1001_trainA_act01_3.jpg      1  \n",
       "4         4.jpg  1001_trainA_act01_4.jpg      1  \n",
       "...         ...                      ...    ...  \n",
       "1825      0.jpg  1007_trainB_act20_0.jpg     20  \n",
       "1826      1.jpg  1007_trainB_act20_1.jpg     20  \n",
       "1827      2.jpg  1007_trainB_act20_2.jpg     20  \n",
       "1828      3.jpg  1007_trainB_act20_3.jpg     20  \n",
       "1829      4.jpg  1007_trainB_act20_4.jpg     20  \n",
       "\n",
       "[1830 rows x 3114 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygJQ81HWnzB0"
   },
   "source": [
    "# Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf7Ig686n45x"
   },
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.metrics import error_rate, accuracy\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJaAYTdNfX-b"
   },
   "outputs": [],
   "source": [
    "valid_pct = 0.2\n",
    "\n",
    "valid_index = []\n",
    "start_idx = 0\n",
    "\n",
    "for idx, key in enumerate(events_text.keys()): \n",
    "    num_entries = df_train[df_train['event_id']==key].shape[0]\n",
    "    num_valid_idx = round(num_entries * valid_pct)\n",
    "    idx = random.sample(range(start_idx, start_idx+num_entries), num_valid_idx)\n",
    "    valid_index += idx\n",
    "    start_idx += num_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAhh29zgoWvi"
   },
   "outputs": [],
   "source": [
    "dep_var = 'label'\n",
    "cat_names = []\n",
    "\n",
    "data_columns = df_train.columns.str.startswith(\"data_\")\n",
    "data_autographer = [not item for item in df_train.columns.str.startswith(\"data_AUTOGRAPHER\")]\n",
    "data_mouse = [not item for item in df_train.columns.str.startswith(\"data_MOUSE\")]\n",
    "cont_names = list(df_train.loc[:, data_columns & data_autographer].columns)\n",
    "\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_autographer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_HR_activity_median',\n",
       " 'data_HR_activity_min',\n",
       " 'data_HR_activity_max',\n",
       " 'data_HR_activity_average',\n",
       " 'data_HR_activity_std',\n",
       " 'data_HR_activity_len',\n",
       " 'data_LEFT_ACC_MAG_median',\n",
       " 'data_LEFT_ACC_MAG_min',\n",
       " 'data_LEFT_ACC_MAG_max',\n",
       " 'data_LEFT_ACC_MAG_average',\n",
       " 'data_LEFT_ACC_MAG_std',\n",
       " 'data_LEFT_ACC_MAG_len',\n",
       " 'data_LEFT_ACC_X_median',\n",
       " 'data_LEFT_ACC_X_min',\n",
       " 'data_LEFT_ACC_X_max',\n",
       " 'data_LEFT_ACC_X_average',\n",
       " 'data_LEFT_ACC_X_std',\n",
       " 'data_LEFT_ACC_X_len',\n",
       " 'data_LEFT_ACC_Y_median',\n",
       " 'data_LEFT_ACC_Y_min',\n",
       " 'data_LEFT_ACC_Y_max',\n",
       " 'data_LEFT_ACC_Y_average',\n",
       " 'data_LEFT_ACC_Y_std',\n",
       " 'data_LEFT_ACC_Y_len',\n",
       " 'data_LEFT_ACC_Z_median',\n",
       " 'data_LEFT_ACC_Z_min',\n",
       " 'data_LEFT_ACC_Z_max',\n",
       " 'data_LEFT_ACC_Z_average',\n",
       " 'data_LEFT_ACC_Z_std',\n",
       " 'data_LEFT_ACC_Z_len',\n",
       " 'data_RIGHT_ACC_MAG_median',\n",
       " 'data_RIGHT_ACC_MAG_min',\n",
       " 'data_RIGHT_ACC_MAG_max',\n",
       " 'data_RIGHT_ACC_MAG_average',\n",
       " 'data_RIGHT_ACC_MAG_std',\n",
       " 'data_RIGHT_ACC_MAG_len',\n",
       " 'data_RIGHT_ACC_X_median',\n",
       " 'data_RIGHT_ACC_X_min',\n",
       " 'data_RIGHT_ACC_X_max',\n",
       " 'data_RIGHT_ACC_X_average',\n",
       " 'data_RIGHT_ACC_X_std',\n",
       " 'data_RIGHT_ACC_X_len',\n",
       " 'data_RIGHT_ACC_Y_median',\n",
       " 'data_RIGHT_ACC_Y_min',\n",
       " 'data_RIGHT_ACC_Y_max',\n",
       " 'data_RIGHT_ACC_Y_average',\n",
       " 'data_RIGHT_ACC_Y_std',\n",
       " 'data_RIGHT_ACC_Y_len',\n",
       " 'data_RIGHT_ACC_Z_median',\n",
       " 'data_RIGHT_ACC_Z_min',\n",
       " 'data_RIGHT_ACC_Z_max',\n",
       " 'data_RIGHT_ACC_Z_average',\n",
       " 'data_RIGHT_ACC_Z_std',\n",
       " 'data_RIGHT_ACC_Z_len',\n",
       " 'data_HEAD_MAG_by_activity_median',\n",
       " 'data_HEAD_MAG_by_activity_min',\n",
       " 'data_HEAD_MAG_by_activity_max',\n",
       " 'data_HEAD_MAG_by_activity_average',\n",
       " 'data_HEAD_MAG_by_activity_std',\n",
       " 'data_HEAD_MAG_by_activity_len',\n",
       " 'data_HEAD_X_by_activity_median',\n",
       " 'data_HEAD_X_by_activity_min',\n",
       " 'data_HEAD_X_by_activity_max',\n",
       " 'data_HEAD_X_by_activity_average',\n",
       " 'data_HEAD_X_by_activity_std',\n",
       " 'data_HEAD_X_by_activity_len',\n",
       " 'data_HEAD_Y_by_activity_median',\n",
       " 'data_HEAD_Y_by_activity_min',\n",
       " 'data_HEAD_Y_by_activity_max',\n",
       " 'data_HEAD_Y_by_activity_average',\n",
       " 'data_HEAD_Y_by_activity_std',\n",
       " 'data_HEAD_Y_by_activity_len',\n",
       " 'data_HEAD_Z_by_activity_median',\n",
       " 'data_HEAD_Z_by_activity_min',\n",
       " 'data_HEAD_Z_by_activity_max',\n",
       " 'data_HEAD_Z_by_activity_average',\n",
       " 'data_HEAD_Z_by_activity_std',\n",
       " 'data_HEAD_Z_by_activity_len',\n",
       " 'data_MOUSE_PIX_DISTS_median',\n",
       " 'data_MOUSE_PIX_DISTS_min',\n",
       " 'data_MOUSE_PIX_DISTS_max',\n",
       " 'data_MOUSE_PIX_DISTS_average',\n",
       " 'data_MOUSE_PIX_DISTS_std',\n",
       " 'data_MOUSE_PIX_DISTS_len',\n",
       " 'data_MOUSE_TIMEDIFFS_median',\n",
       " 'data_MOUSE_TIMEDIFFS_min',\n",
       " 'data_MOUSE_TIMEDIFFS_max',\n",
       " 'data_MOUSE_TIMEDIFFS_average',\n",
       " 'data_MOUSE_TIMEDIFFS_std',\n",
       " 'data_MOUSE_TIMEDIFFS_len',\n",
       " 'data_MOUSE_VELOCITY_median',\n",
       " 'data_MOUSE_VELOCITY_min',\n",
       " 'data_MOUSE_VELOCITY_max',\n",
       " 'data_MOUSE_VELOCITY_average',\n",
       " 'data_MOUSE_VELOCITY_std',\n",
       " 'data_MOUSE_VELOCITY_len',\n",
       " 'data_EOG_UD_by_activity_median',\n",
       " 'data_EOG_UD_by_activity_min',\n",
       " 'data_EOG_UD_by_activity_max',\n",
       " 'data_EOG_UD_by_activity_average',\n",
       " 'data_EOG_UD_by_activity_std',\n",
       " 'data_EOG_UD_by_activity_len',\n",
       " 'data_EOG_LR_by_activity_median',\n",
       " 'data_EOG_LR_by_activity_min',\n",
       " 'data_EOG_LR_by_activity_max',\n",
       " 'data_EOG_LR_by_activity_average',\n",
       " 'data_EOG_LR_by_activity_std',\n",
       " 'data_EOG_LR_by_activity_len']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(data_autographer) - np.sum(np.asarray(data_autographer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7Xs0xyutHpt"
   },
   "outputs": [],
   "source": [
    "# data = (TabularList.from_df(df_train, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "#                            .split_by_rand_pct(valid_pct=0.2, seed=43)\n",
    "#                            .label_from_df(cols=dep_var)\n",
    "#                            .add_test(test)\n",
    "#                            .databunch())\n",
    "train_tabular_list = TabularList.from_df(df_train, cont_names=cont_names, procs=procs, path='./')\n",
    "train_image_list = ImageList.from_df(df_train, path=IMG_DIR, cols='image_path')\n",
    "\n",
    "# test_tabular_list = TabularList.from_df(df_test, cat_names=cat_names, cont_names=cont_names, procs=procs, path='./')\n",
    "# test_image_list = ImageList.from_df(df_test, path=IMG_DIR, cols='spectrogram_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e6sL8-7mA0q"
   },
   "outputs": [],
   "source": [
    "#test_mixed_list = MixedItemList([test_image_list, test_tabular_list], path='./')\n",
    "        \n",
    "train_mixed_list = (MixedItemList([train_image_list, train_tabular_list], path='./', inner_df=train_tabular_list.inner_df)\n",
    ".split_by_idx(valid_index)\n",
    ".label_from_df(cols=dep_var, label_cls=CategoryList))\n",
    "#.add_test(test_mixed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_mixed_list.databunch(bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78b1f8dd8386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.train_ds.x.item_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghG0bRWhYiWx"
   },
   "outputs": [],
   "source": [
    "class ImageTabularModel(nn.Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, emb_szs:ListSizes, n_cont:int, layers:Collection[int], ps:Collection[float]=None):\n",
    "        super().__init__()\n",
    "        self.cnn = create_body(models.resnet34,pretrained = True) #resnet34 for images\n",
    "        self.tab = TabularModel(emb_szs, n_cont, 128, layers, use_bn = False, emb_drop = ps) #Tabular model for metadata\n",
    "\n",
    "        self.reduce = nn.Sequential(*([AdaptiveConcatPool2d(), Flatten()] + bn_drop_lin((1024), 512, bn=True, p=0.3, actn=nn.ReLU(inplace=True)))) #Use this FC layers to reduce nodes\n",
    "        self.merge = nn.Sequential(*bn_drop_lin(512 + 128, 128, bn=True, actn=nn.ReLU(inplace=True))) #Merge 2 models together\n",
    "        self.final = nn.Sequential(*bn_drop_lin(128, 20, bn=True, p=0.)) # Last FC layer for regression\n",
    "\n",
    "    def forward(self, img:Tensor, x:Tensor) -> Tensor:\n",
    "        imgLatent = self.reduce(self.cnn(img))\n",
    "        tabLatent = self.tab(x[0],x[1])\n",
    "        cat = torch.cat([imgLatent, tabLatent], dim=1) #re-define forward func for concat model\n",
    "        merge = self.merge(cat)\n",
    "        final = self.final(merge)\n",
    "        return final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "ac947cdb526141ba8598d75064439886",
      "bb8b002348b8461092ceafdc39f5ae92",
      "44bd64f387304f3684d71e767b13acc3",
      "b9e0e83c62b54872a1ddc4c08e92ec16",
      "155d863ede66442dbe3f1dee3e55fa0a",
      "7d47dba5928242a494d3c90426be2c9e",
      "2d10fa5b546a4716a86402d1c7b939f1",
      "c565188ff4164a809d94477e93ed8368"
     ]
    },
    "colab_type": "code",
    "id": "WAVtNnf5aLe7",
    "outputId": "72ca67e4-4886-4073-e0b9-c12534f8587f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/hong01/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:02<00:00, 30.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "data = train_mixed_list.databunch(bs=4)\n",
    "emb = data.train_ds.x.item_lists[1].get_emb_szs()\n",
    "model = ImageTabularModel(emb, 0, [1000,500], ps=0.2)\n",
    "\n",
    "learn = Learner(data, model, metrics=[accuracy], loss_func=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Imypto5jJlf9",
    "outputId": "97cd9a8a-54bc-45e0-b9fb-2159caffade0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category 7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds.y[555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m443z_bku9EC"
   },
   "outputs": [],
   "source": [
    "#learn = tabular_learner(data, layers=[2000,1000], metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "0T6Git8SvrfL",
    "outputId": "7c88ed0c-212e-4471-dab2-b17d422fc25e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.00% [1/20 05:52<1:51:41]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.647188</td>\n",
       "      <td>2.576297</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>05:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='190' class='' max='366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      51.91% [190/366 02:51<02:39 2.6738]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-35ab60084846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;34m\"Handle gradient calculation on `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(250, 1e-3, callbacks = SaveModelCallback(learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0moLG-vl9Ws"
   },
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCoDOVyYvt07"
   },
   "outputs": [],
   "source": [
    "learn.load('stage-1')\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4rnIu07wIpG"
   },
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(5, slice(1e-3), callbacks = SaveModelCallback(learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XQBXhJHwSxG"
   },
   "outputs": [],
   "source": [
    "# predictions, *_ = learn.get_preds(DatasetType.Test)\n",
    "# labels = np.argmax(predictions, 1)\n",
    "# df_test['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y5xQFYio9dwb"
   },
   "outputs": [],
   "source": [
    "pred_test, y_test = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T73bdKHcw27A"
   },
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N9GjWpsfA_Z"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_Vybv1TUzwe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4febcb91cd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learn.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "learn = joblib.load('learn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mart_image_tabular_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "155d863ede66442dbe3f1dee3e55fa0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2d10fa5b546a4716a86402d1c7b939f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44bd64f387304f3684d71e767b13acc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d47dba5928242a494d3c90426be2c9e",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_155d863ede66442dbe3f1dee3e55fa0a",
      "value": 87306240
     }
    },
    "7d47dba5928242a494d3c90426be2c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac947cdb526141ba8598d75064439886": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44bd64f387304f3684d71e767b13acc3",
       "IPY_MODEL_b9e0e83c62b54872a1ddc4c08e92ec16"
      ],
      "layout": "IPY_MODEL_bb8b002348b8461092ceafdc39f5ae92"
     }
    },
    "b9e0e83c62b54872a1ddc4c08e92ec16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c565188ff4164a809d94477e93ed8368",
      "placeholder": "​",
      "style": "IPY_MODEL_2d10fa5b546a4716a86402d1c7b939f1",
      "value": " 83.3M/83.3M [00:00&lt;00:00, 112MB/s]"
     }
    },
    "bb8b002348b8461092ceafdc39f5ae92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c565188ff4164a809d94477e93ed8368": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
