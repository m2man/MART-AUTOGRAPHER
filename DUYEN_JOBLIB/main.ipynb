{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "AUTOGRAPHER_FILE = 'autographer_embeded_ft_train.joblib'\n",
    "TABULAR_FILE = 'tabular_embeded_ft_train.joblib'\n",
    "TAB_AND_IMG_FILE = 'tabular_with_images_train.joblib' # No need for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "autographer_feat = joblib.load(AUTOGRAPHER_FILE)\n",
    "tabular_feat = joblib.load(TABULAR_FILE)\n",
    "df = joblib.load(TAB_AND_IMG_FILE)\n",
    "groundtruths = {}\n",
    "for i, l in zip(df['image_path'], df['label']):\n",
    "    groundtruths['_'.join(i.split('_')[:-1])] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Instance:\n",
    "    def __init__(self, id, key):\n",
    "        self.id = id\n",
    "        self.tab = tabular_feat[key]\n",
    "        self.images = np.stack(autographer_feat[key]['features'])\n",
    "        self.images_path = autographer_feat[key]['images']\n",
    "        self.label = groundtruths[key]\n",
    "instance = Instance(0, '1001_trainA_act01')\n",
    "instance.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(512 + 128, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5))\n",
    "            \n",
    "        self.rnn = nn.GRU(512, 512, 2, dropout=0.5, bidirectional=True)\n",
    "        self.mlp2 = nn.Linear(512, 512)\n",
    "        \n",
    "    def forward(self, tab, images):\n",
    "        # images: seq len, batch size, 512\n",
    "        # tab: batch size, 128\n",
    "        tab = tab.repeat((images.shape[0], 1, 1))\n",
    "        features = self.mlp(torch.cat([images, tab], dim=2))\n",
    "        _, hidden = self.rnn(features)\n",
    "        \n",
    "        return self.mlp2(hidden[-1]) # batch size, 512\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, feat1, feat2):\n",
    "        dist = torch.abs(feat1-feat2)\n",
    "        mul = torch.mul(feat1, feat2)\n",
    "        return self.mlp(torch.cat([feat1, feat2, dist, mul], dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPLIT 0\n",
      "Epoch 0: [train loss: 0.1328] [val loss: 1.0000, 1.0000, 0.0231]\n",
      "Saved\n",
      "Epoch 1: [train loss: 0.1195] [val loss: 1.0000, 1.0000, 0.0267]\n",
      "Epoch 2: [train loss: 0.1199] [val loss: 1.0000, 1.0000, 0.0303]\n",
      "Epoch 3: [train loss: 0.1465] [val loss: 0.9894, 0.9249, 0.0610]\n",
      "Epoch 4: [train loss: 0.1228] [val loss: 0.9969, 0.9664, 0.0381]\n",
      "================================================================================\n",
      "SPLIT 1\n",
      "Epoch 0: [train loss: 0.1359] [val loss: 1.0000, 1.0000, 0.0258]\n",
      "Saved\n",
      "Epoch 1: [train loss: 0.1197] [val loss: 1.0000, 1.0000, 0.0202]\n",
      "Saved\n",
      "Epoch 2: [train loss: 0.1673] [val loss: 0.9955, 0.9604, 0.0399]\n",
      "Epoch 3: [train loss: 0.1280] [val loss: 1.0000, 1.0000, 0.0301]\n",
      "Epoch 4: [train loss: 0.1195] [val loss: 1.0000, 1.0000, 0.0283]\n",
      "================================================================================\n",
      "SPLIT 2\n",
      "Epoch 0: [train loss: 0.1341] [val loss: 0.9992, 0.9855, 0.0276]\n",
      "Saved\n",
      "Epoch 1: [train loss: 0.1196] [val loss: 0.9991, 0.9835, 0.0285]\n",
      "Epoch 2: [train loss: 0.1198] [val loss: 0.9991, 0.9835, 0.0314]\n",
      "Epoch 3: [train loss: 0.1449] [val loss: 0.9967, 0.9671, 0.0278]\n",
      "Epoch 4: [train loss: 0.1194] [val loss: 0.9975, 0.9729, 0.0349]\n",
      "================================================================================\n",
      "SPLIT 3\n",
      "Epoch 0: [train loss: 0.1322] [val loss: 1.0000, 0.9900, 0.0310]\n",
      "Saved\n",
      "Epoch 1: [train loss: 0.1193] [val loss: 1.0000, 0.9900, 0.0191]\n",
      "Saved\n",
      "Epoch 2: [train loss: 0.1195] [val loss: 1.0000, 0.9900, 0.0273]\n",
      "Epoch 3: [train loss: 0.1585] [val loss: 0.9630, 0.7605, 0.1410]\n",
      "Epoch 4: [train loss: 0.1307] [val loss: 0.9967, 0.9564, 0.0374]\n",
      "================================================================================\n",
      "SPLIT 4\n",
      "Epoch 0: [train loss: 0.1361] [val loss: 1.0000, 1.0000, 0.0250]\n",
      "Saved\n",
      "Epoch 1: [train loss: 0.1191] [val loss: 1.0000, 1.0000, 0.0222]\n",
      "Saved\n",
      "Epoch 2: [train loss: 0.1195] [val loss: 1.0000, 1.0000, 0.0289]\n",
      "Epoch 3: [train loss: 0.1458] [val loss: 0.9964, 0.9631, 0.0372]\n",
      "Epoch 4: [train loss: 0.1195] [val loss: 0.9958, 0.9552, 0.0366]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=80, random_state=0)\n",
    "train_instances = np.array([Instance(i, key) for i, key in enumerate(tabular_feat.keys())])\n",
    "\n",
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, instances, k, valid=False):\n",
    "        super(PairwiseDataset, self).__init__()\n",
    "        self.instances = instances\n",
    "        self.combinations = list(itertools.product(range(len(instances)), repeat=2))\n",
    "        self.weights = [10 if instances[comb[0]].label == instances[comb[1]].label else 1 for comb in self.combinations]\n",
    "        self.samples = random.choices(self.combinations, weights=self.weights, k=k)\n",
    "        self.k = k\n",
    "        self.valid = valid\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.valid:\n",
    "            return len(self.combinations)\n",
    "        return len(self.samples)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.samples = random.choices(self.combinations, weights=self.weights, k=self.k)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        samples = self.samples\n",
    "        if self.valid:\n",
    "            samples = self.combinations\n",
    "        instances1 = self.instances[samples[i][0]]\n",
    "        instances2 = self.instances[samples[i][1]]\n",
    "        if instances1.label == instances2.label:\n",
    "            label = 1 - (1 - self.valid) * random.random() / 20\n",
    "        else:\n",
    "            label = (1 - self.valid) * random.random() / 20\n",
    "        return instances1, instances2, label\n",
    "\n",
    "def collate_fn(pairs):\n",
    "    instances1, instances2, labels = zip(*pairs)\n",
    "    tab1 = torch.tensor([instance.tab for instance in instances1]).squeeze(1).float().cuda()\n",
    "    tab2 = torch.tensor([instance.tab for instance in instances2]).squeeze(1).float().cuda()\n",
    "    images1 = nn.utils.rnn.pad_sequence([torch.tensor(instance.images) for instance in instances1]).float().cuda()\n",
    "    images2 = nn.utils.rnn.pad_sequence([torch.tensor(instance.images) for instance in instances2]).float().cuda()\n",
    "    labels = torch.tensor(labels).float().cuda()\n",
    "    return tab1, images1, tab2, images2, labels\n",
    "\n",
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "        assert y_true.ndim == 1\n",
    "        assert y_pred.ndim == 1 \n",
    "\n",
    "        tp = (y_true * y_pred).sum().to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
    "\n",
    "        epsilon = 1e-7\n",
    "\n",
    "        precision = tp / (tp + fp + epsilon)\n",
    "        recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "        f1.requires_grad = is_training\n",
    "        return f1\n",
    "    \n",
    "for split, (train_index, test_index) in enumerate(sss.split(train_instances, [instance.label for instance in train_instances])):\n",
    "    train = PairwiseDataset(train_instances[train_index], k=80000)\n",
    "    valid = PairwiseDataset(train_instances[test_index], k=1000, valid=True)\n",
    "    bce = nn.BCELoss()\n",
    "    bce.cuda()\n",
    "    embedder = Embedder()\n",
    "    discriminator = Discriminator()\n",
    "    embedder.cuda()\n",
    "    discriminator.cuda()\n",
    "    optimizer = torch.optim.Adam(itertools.chain(embedder.parameters(), discriminator.parameters()), lr=1e-3)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SPLIT\", split)\n",
    "    best_val = 100\n",
    "    for epoch in range(5):\n",
    "        train.shuffle()\n",
    "        train_dataloader = DataLoader(train, batch_size=64, collate_fn=collate_fn)\n",
    "        embedder.train()\n",
    "        discriminator.train()\n",
    "        total_loss = []\n",
    "        for i, (tab1, images1, tab2, images2, labels) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            emb1 = embedder(tab1, images1)\n",
    "            emb2 = embedder(tab2, images2)\n",
    "            preds = discriminator(emb1, emb2)\n",
    "            loss = bce(preds.squeeze(), labels.squeeze())\n",
    "            loss.backward()\n",
    "            total_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch}: [train loss: {np.mean(total_loss):.4f}]\", end=\" \")\n",
    "        acc = 0\n",
    "        total_loss = []\n",
    "        f1 = []\n",
    "        with torch.no_grad():\n",
    "            embedder.eval()\n",
    "            discriminator.eval()\n",
    "            count = 0\n",
    "            valid_dataloader = DataLoader(valid, batch_size=64, collate_fn=collate_fn)\n",
    "            for i, (tab1, images1, tab2, images2, labels) in enumerate(valid_dataloader):\n",
    "                emb1 = embedder(tab1, images1)\n",
    "                emb2 = embedder(tab2, images2)\n",
    "                preds = discriminator(emb1, emb2)\n",
    "                acc += sum((preds.round().squeeze() == labels.squeeze()).float()).item()\n",
    "                f1.append(f1_loss(labels.squeeze(), preds.round().squeeze()).item())\n",
    "                total_loss.append(bce(preds.squeeze(), labels.squeeze()).item())\n",
    "                count += 1\n",
    "            total_loss = np.mean(total_loss)\n",
    "            print(f\"[val loss: {acc/len(valid):.4f}, {np.mean(f1):.4f}, {total_loss:.4f}]\")\n",
    "            if total_loss < best_val:\n",
    "                best_val = total_loss\n",
    "                torch.save({\"embedder\": embedder.state_dict(),\n",
    "                \"discriminator\": discriminator.state_dict()}, f\"model_{split}.bin\")\n",
    "                print(\"Saved\")\n",
    "            else:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.load(\"model_full.bin\")\n",
    "embedder.load_state_dict(states[\"embedder\"])\n",
    "discriminator.load_state_dict(states[\"discriminator\"])\n",
    "\n",
    "from collections import defaultdict\n",
    "embedder.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "def rank(embedder, discriminator, example):\n",
    "    tab1 = torch.tensor([example.tab]).squeeze(1).float().cuda()\n",
    "    images1 = torch.tensor(example.images).float().unsqueeze(1).float().cuda()\n",
    "    emb1 = embedder(tab1, images1)\n",
    "    scores = defaultdict(lambda: [])\n",
    "    for instance in train_instances:\n",
    "        if instance.id != example.id:\n",
    "            tab2 = torch.tensor([instance.tab]).squeeze(1).float().cuda()\n",
    "            images2 = torch.tensor(instance.images).unsqueeze(1).float().cuda()\n",
    "            emb2 = embedder(tab2, images2)\n",
    "            pred = discriminator(emb1, emb2)\n",
    "            scores[instance.label].append(pred.item())\n",
    "    ave_scores = np.zeros(20)\n",
    "    for label in scores:\n",
    "        ave_scores[int(label) - 1] = np.mean(scores[label])\n",
    "    return np.argmax(ave_scores) + 1, ave_scores\n",
    "\n",
    "# acc = 0\n",
    "# for i, example in enumerate(train_instances[200:]):\n",
    "#     pred, scores = rank(example)\n",
    "#     acc += pred == example.label\n",
    "#     print(f\"{i}, {pred}({scores[pred - 1]:.4f}), {example.label}({scores[example.label-1]:.4f})\")\n",
    "# #     print(scores)\n",
    "    \n",
    "# print(acc, len(instances[200:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autographer_feat_test = joblib.load(\"autographer_embeded_ft_test.joblib\")\n",
    "tabular_feat_test = joblib.load('tabular_embeded_ft_test.joblib')\n",
    "class TestInstance:\n",
    "    def __init__(self, id, key):\n",
    "        self.id = -1\n",
    "        self.tab = tabular_feat_test['_test_'.join(key.split('_'))]\n",
    "        self.images = np.stack(autographer_feat_test[key]['features'])\n",
    "        self.images_path = autographer_feat_test[key]['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_instances = [TestInstance(i, key) for i, key in enumerate(autographer_feat_test.keys())]\n",
    "acts = {'act00': 'calibration',\n",
    "                'act01': 'write an email',\n",
    "                'act02': 'read on screen',\n",
    "                'act03': 'edit/create presentation',\n",
    "                'act04': 'zone out and fixate',\n",
    "                'act05': 'use a calculator to add up numbers on sheet',\n",
    "                'act06': 'physical precision task',\n",
    "                'act07': 'put documents in order',\n",
    "                'act08': 'read text/numbers on page',\n",
    "                'act09': 'arrange money in change jar',\n",
    "                'act10': 'write on paper with pen',\n",
    "                'act11': 'watch a youtube video',\n",
    "                'act12': 'go to a news website and browse',\n",
    "                'act13': 'have conversation with experimenter in room',\n",
    "                'act14': 'make a telephone call',\n",
    "                'act15': 'drink/eat for 2 minutes',\n",
    "                'act16': 'close eyes and sit still',\n",
    "                'act17': 'clean e.g. sweaping the floor, wipe, ...',\n",
    "                'act18': 'exercise: sit up/stand down repeatedly',\n",
    "                'act19': 'hand-eye coordination (tennis ball)',\n",
    "                'act20': 'pace the room',\n",
    "                }\n",
    "acts = list(acts.values())\n",
    "\n",
    "results = np.zeros((5, 140, 20))\n",
    "for split in range(5):\n",
    "    states = torch.load(f\"model_{split}.bin\")\n",
    "    embedder.load_state_dict(states[\"embedder\"])\n",
    "    discriminator.load_state_dict(states[\"discriminator\"])\n",
    "    embedder.eval()\n",
    "    discriminator.eval()\n",
    "    print(\"Split\", split)\n",
    "    for i, (example, key) in tqdm(enumerate(zip(test_instances, autographer_feat_test.keys()))):\n",
    "        pred, scores = rank(embedder, discriminator, example)\n",
    "        results[split][i] = scores\n",
    "\n",
    "results = np.mean(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:00, 3609.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001_pred13, close eyes and sit still(0.7701)\n",
      "[0.02461336 0.03841531 0.02636391 0.03541568 0.02967007 0.02600539\n",
      " 0.02593976 0.02633449 0.02674963 0.02441375 0.04248182 0.02974187\n",
      " 0.02678906 0.02624479 0.02636072 0.77014856 0.02794314 0.02906855\n",
      " 0.03234492 0.02919026]\n",
      "1001_pred5, edit/create presentation(0.9790)\n",
      "[0.01928134 0.0190859  0.97895494 0.02033642 0.02256728 0.02106243\n",
      " 0.02185508 0.02149156 0.02059488 0.01970595 0.02188001 0.0209347\n",
      " 0.02303529 0.01930667 0.02100879 0.02016639 0.02409818 0.02201975\n",
      " 0.02410177 0.02004935]\n",
      "1001_pred1, hand-eye coordination (tennis ball)(0.3693)\n",
      "[0.02309726 0.02268305 0.0244991  0.02392099 0.02548504 0.02422896\n",
      " 0.07877237 0.02685663 0.05623076 0.02460905 0.02537168 0.02609237\n",
      " 0.08519916 0.02352702 0.02763739 0.02384712 0.05051963 0.02642674\n",
      " 0.36927993 0.02657825]\n",
      "1001_pred0, read on screen(0.6760)\n",
      "[0.0246887  0.6759922  0.02579843 0.02597566 0.0289671  0.02648293\n",
      " 0.02607246 0.02766692 0.02460387 0.02542542 0.08749788 0.10464744\n",
      " 0.02734283 0.0293312  0.0265959  0.02679786 0.02572446 0.02811368\n",
      " 0.03090789 0.02770529]\n",
      "1001_pred14, write on paper with pen(0.6428)\n",
      "[0.02383335 0.02511426 0.02659184 0.02634185 0.10756362 0.02576851\n",
      " 0.02760688 0.03168583 0.02347831 0.64276583 0.02497307 0.02909348\n",
      " 0.02878475 0.02355041 0.02651219 0.02684043 0.02965831 0.02727747\n",
      " 0.02964146 0.02635436]\n",
      "1001_pred11, clean e.g. sweaping the floor, wipe, ...(0.9800)\n",
      "[0.02124604 0.01932245 0.02406115 0.01932417 0.02521433 0.02043704\n",
      " 0.01989308 0.02169945 0.01976381 0.0219063  0.02218251 0.0219801\n",
      " 0.019859   0.01998916 0.02209953 0.022094   0.98002705 0.02133553\n",
      " 0.02390428 0.0217915 ]\n",
      "1001_pred4, put documents in order(0.8045)\n",
      "[0.024506   0.02648207 0.02564064 0.0239699  0.02879101 0.02367713\n",
      " 0.80453712 0.02903031 0.0223801  0.02708808 0.02734675 0.03047257\n",
      " 0.03736642 0.02502984 0.027844   0.02570152 0.04094389 0.02760208\n",
      " 0.06628583 0.02430699]\n",
      "1001_pred12, read text/numbers on page(0.9619)\n",
      "[0.01993089 0.02273527 0.02089497 0.02305937 0.02243787 0.01924382\n",
      " 0.02109651 0.96186159 0.01796735 0.02337004 0.02107691 0.02272991\n",
      " 0.02535355 0.01992751 0.02315044 0.02141456 0.02202884 0.0229431\n",
      " 0.02503654 0.02079129]\n",
      "1001_pred10, arrange money in change jar(0.7282)\n",
      "[0.02542784 0.02483453 0.02691492 0.02649182 0.02659327 0.03903847\n",
      " 0.12581109 0.02530332 0.72815078 0.02483175 0.02840283 0.0246176\n",
      " 0.0304237  0.02520605 0.02989469 0.0274202  0.02783643 0.02983957\n",
      " 0.03445709 0.02630522]\n",
      "1001_pred8, physical precision task(0.9724)\n",
      "[0.02134264 0.0226349  0.0228164  0.02234403 0.02223278 0.97242219\n",
      " 0.02102683 0.02107855 0.01877618 0.02044585 0.02263993 0.02142771\n",
      " 0.02197824 0.02070959 0.02284236 0.0225086  0.02283004 0.02513516\n",
      " 0.02631501 0.02232289]\n",
      "1001_pred16, go to a news website and browse(0.9395)\n",
      "[0.02858214 0.02591096 0.04076996 0.02369767 0.02585945 0.02124082\n",
      " 0.02437856 0.02418755 0.02040842 0.02634983 0.02442658 0.93946481\n",
      " 0.02782421 0.02136213 0.02261246 0.02455959 0.02561404 0.0245829\n",
      " 0.0288943  0.02241195]\n",
      "1001_pred9, have conversation with experimenter in room(0.9587)\n",
      "[0.02315368 0.0240536  0.02729162 0.02501623 0.02653294 0.02394996\n",
      " 0.02485254 0.02715039 0.02313907 0.02628567 0.02410859 0.02827631\n",
      " 0.95874234 0.0258428  0.0294463  0.0253933  0.02352822 0.0269979\n",
      " 0.03367575 0.02305322]\n",
      "1001_pred15, zone out and fixate(0.9743)\n",
      "[0.01933761 0.02205327 0.02148606 0.97426346 0.02584122 0.02175503\n",
      " 0.01968395 0.02251135 0.02178226 0.0206126  0.01949751 0.02289155\n",
      " 0.02227872 0.01942951 0.02442914 0.02341612 0.02149052 0.02080353\n",
      " 0.02540672 0.02076345]\n",
      "1001_pred19, pace the room(0.9636)\n",
      "[0.02106639 0.02364652 0.02260084 0.02246593 0.0259     0.02503012\n",
      " 0.02217135 0.02453055 0.02361841 0.02302368 0.02655436 0.02415099\n",
      " 0.02402744 0.02260259 0.02481197 0.02695541 0.02497868 0.03374482\n",
      " 0.02739517 0.96363146]\n",
      "1001_pred6, exercise: sit up/stand down repeatedly(0.9258)\n",
      "[0.02354058 0.0254929  0.02545219 0.02400065 0.02890732 0.02811997\n",
      " 0.0256067  0.02717189 0.02619908 0.02412746 0.02745744 0.02598223\n",
      " 0.02597052 0.02407584 0.02487356 0.02752838 0.02599824 0.92580655\n",
      " 0.03106779 0.04960699]\n",
      "1001_pred2, drink/eat for 2 minutes(0.9560)\n",
      "[0.02584325 0.02375368 0.02619814 0.02680314 0.02919273 0.02543856\n",
      " 0.02816836 0.02736265 0.025557   0.02459951 0.02852316 0.02529382\n",
      " 0.02931143 0.03081078 0.95598315 0.02811149 0.02752149 0.02652839\n",
      " 0.03188119 0.0293047 ]\n",
      "1001_pred7, watch a youtube video(0.9655)\n",
      "[0.02249017 0.02583211 0.02494949 0.02137193 0.02764368 0.02525508\n",
      " 0.0256099  0.02444003 0.02550722 0.02236231 0.96546796 0.02663687\n",
      " 0.02488194 0.02572049 0.02677305 0.02495843 0.02558873 0.02735424\n",
      " 0.02790814 0.02635272]\n",
      "1001_pred17, make a telephone call(0.9055)\n",
      "[0.02320452 0.0238104  0.02856865 0.02445604 0.02957631 0.02368388\n",
      " 0.0266705  0.02626744 0.02459641 0.02409639 0.0266866  0.02682347\n",
      " 0.02978356 0.90553953 0.0298533  0.02764952 0.02861044 0.02617716\n",
      " 0.03008215 0.02351953]\n",
      "1001_pred3, write an email(0.9834)\n",
      "[0.98338348 0.01967977 0.02145593 0.01900304 0.02180633 0.02113775\n",
      " 0.02009012 0.02128705 0.02000991 0.01916062 0.02088125 0.02200442\n",
      " 0.02119944 0.01792611 0.02311235 0.0202349  0.02266262 0.02199395\n",
      " 0.02757526 0.0192673 ]\n",
      "1001_pred18, write on paper with pen(0.9753)\n",
      "[0.01910018 0.02044008 0.02043383 0.0204469  0.02302886 0.01964987\n",
      " 0.02235994 0.02457187 0.01893638 0.97531977 0.01974208 0.0236687\n",
      " 0.02352789 0.01819526 0.02110651 0.02102867 0.02334844 0.02079145\n",
      " 0.02420379 0.02112105]\n",
      "1002_pred10, edit/create presentation(0.2083)\n",
      "[0.12308201 0.02954036 0.2083068  0.02827555 0.04941266 0.02718646\n",
      " 0.03074007 0.03100637 0.02874122 0.07290092 0.02838606 0.14021957\n",
      " 0.03067979 0.02407132 0.02708774 0.02817055 0.03236942 0.02946972\n",
      " 0.03268148 0.02682043]\n",
      "1002_pred11, put documents in order(0.9796)\n",
      "[0.01883904 0.02009659 0.02154456 0.01882136 0.02403954 0.01968276\n",
      " 0.97964806 0.02103559 0.01615069 0.02160802 0.02189723 0.02113721\n",
      " 0.02199992 0.02065759 0.02352677 0.02085454 0.02032593 0.02215508\n",
      " 0.02211667 0.01913436]\n",
      "1002_pred18, close eyes and sit still(0.4087)\n",
      "[0.02710811 0.03131729 0.03621029 0.02851325 0.03269615 0.02777565\n",
      " 0.02911527 0.02689273 0.02963494 0.02707746 0.34191099 0.03528093\n",
      " 0.02941146 0.04347177 0.03020414 0.40867135 0.03042393 0.03136115\n",
      " 0.03398435 0.03162398]\n",
      "1002_pred6, drink/eat for 2 minutes(0.9685)\n",
      "[0.02416251 0.02245079 0.02486237 0.02618612 0.02650639 0.02378915\n",
      " 0.02710114 0.02638755 0.02445467 0.02321889 0.02676241 0.02370525\n",
      " 0.02953802 0.0289833  0.96847097 0.02550254 0.02541528 0.02507103\n",
      " 0.02940289 0.02454375]\n",
      "1002_pred0, watch a youtube video(0.6894)\n",
      "[0.02675107 0.02926239 0.04609937 0.02740052 0.03306109 0.02803559\n",
      " 0.02809248 0.02708203 0.02848099 0.025518   0.68941798 0.03646006\n",
      " 0.03137104 0.04808776 0.03048949 0.03962203 0.02934911 0.03230274\n",
      " 0.03406027 0.02984058]\n",
      "1002_pred2, arrange money in change jar(0.9276)\n",
      "[0.02446657 0.02353037 0.02585289 0.02541198 0.02426558 0.03067204\n",
      " 0.0271317  0.02357468 0.92757213 0.02293932 0.02846483 0.0238349\n",
      " 0.0266682  0.02393368 0.02703218 0.02746131 0.02555187 0.02841637\n",
      " 0.02889335 0.0240683 ]\n",
      "1002_pred8, exercise: sit up/stand down repeatedly(0.9470)\n",
      "[0.02607304 0.02384451 0.0272723  0.02374866 0.0291938  0.02864427\n",
      " 0.02665506 0.02621359 0.02669836 0.02431804 0.02942371 0.02627554\n",
      " 0.02604747 0.02412354 0.02544177 0.02735335 0.02564774 0.9469719\n",
      " 0.02789854 0.03182289]\n",
      "1002_pred19, edit/create presentation(0.9777)\n",
      "[0.01976497 0.01984199 0.97766677 0.02069704 0.02295699 0.02132295\n",
      " 0.02211832 0.02176201 0.02087283 0.02002327 0.02221188 0.02187483\n",
      " 0.02340348 0.01930242 0.02123299 0.02037953 0.02422313 0.02224117\n",
      " 0.02448957 0.02022529]\n",
      "1002_pred13, pace the room(0.9360)\n",
      "[0.02300791 0.02489393 0.02629602 0.02308862 0.02794425 0.02460522\n",
      " 0.02432408 0.02568889 0.02397351 0.02515882 0.02781271 0.02537341\n",
      " 0.02425681 0.02429227 0.02650304 0.02821552 0.04795695 0.02453098\n",
      " 0.03067882 0.9359777 ]\n",
      "1002_pred15, edit/create presentation(0.9344)\n",
      "[0.06516192 0.02176583 0.93439101 0.02375807 0.02632503 0.02437015\n",
      " 0.02440656 0.02457674 0.02309574 0.02319333 0.02449168 0.02628303\n",
      " 0.0265616  0.0239268  0.02459269 0.0241758  0.03036665 0.02524359\n",
      " 0.02772829 0.02302574]\n",
      "1002_pred1, go to a news website and browse(0.4617)\n",
      "[0.02571394 0.10175632 0.07045355 0.02575485 0.03219211 0.02302817\n",
      " 0.02523991 0.02841671 0.02220756 0.0287895  0.04220881 0.46173817\n",
      " 0.02729017 0.02352836 0.0246061  0.03001293 0.02678268 0.02604807\n",
      " 0.03110578 0.02379245]\n",
      "1002_pred3, write an email(0.9824)\n",
      "[0.98242747 0.02045999 0.0220012  0.01976741 0.02268656 0.02257507\n",
      " 0.02084152 0.02195989 0.02054346 0.02011959 0.02199911 0.02270434\n",
      " 0.0220453  0.01879248 0.0242773  0.0209662  0.02377343 0.02286146\n",
      " 0.02838017 0.02024291]\n",
      "1002_pred4, physical precision task(0.9730)\n",
      "[0.02221556 0.02310601 0.02346298 0.02266519 0.02250509 0.97300307\n",
      " 0.02204723 0.02173235 0.01947586 0.02123588 0.02347069 0.02201027\n",
      " 0.02288216 0.0214617  0.02325688 0.02300309 0.02350879 0.02597583\n",
      " 0.02672709 0.02271166]\n",
      "1002_pred12, clean e.g. sweaping the floor, wipe, ...(0.9803)\n",
      "[0.0215827  0.01967249 0.02422652 0.0195875  0.02553899 0.02089727\n",
      " 0.02051423 0.02210637 0.02018652 0.02239137 0.02252133 0.0220729\n",
      " 0.02010597 0.02030658 0.02252751 0.02240073 0.9803049  0.02163412\n",
      " 0.02384612 0.02210558]\n",
      "1002_pred14, go to a news website and browse(0.9570)\n",
      "[0.02493937 0.02833951 0.03540748 0.02443076 0.02550049 0.02206896\n",
      " 0.02358996 0.02547703 0.02049412 0.02552009 0.02503739 0.95700513\n",
      " 0.02835257 0.0216087  0.02285715 0.02579764 0.02464434 0.02467596\n",
      " 0.03076241 0.0229667 ]\n",
      "1002_pred5, close eyes and sit still(0.6484)\n",
      "[0.02399457 0.02499235 0.0258582  0.02741267 0.0382204  0.02581281\n",
      " 0.02624379 0.02523642 0.02653415 0.02549948 0.02938487 0.02643041\n",
      " 0.02810903 0.02726691 0.12468376 0.64839303 0.02888024 0.02736022\n",
      " 0.02934708 0.03611995]\n",
      "1002_pred16, have conversation with experimenter in room(0.4521)\n",
      "[0.02524112 0.02590067 0.02816106 0.02938995 0.03159138 0.02543732\n",
      " 0.02783464 0.02995732 0.02761382 0.02703441 0.02780455 0.02878271\n",
      " 0.45212018 0.02804432 0.39520617 0.06116093 0.02760138 0.02874601\n",
      " 0.03779547 0.02423525]\n",
      "1002_pred17, hand-eye coordination (tennis ball)(0.9746)\n",
      "[0.02391282 0.02188226 0.02239383 0.02253657 0.0244355  0.02251358\n",
      " 0.02133767 0.024689   0.02173157 0.02237741 0.02226058 0.02552031\n",
      " 0.02499243 0.02141268 0.02367495 0.02265617 0.02257036 0.02288532\n",
      " 0.97462065 0.02182375]\n",
      "1002_pred7, read text/numbers on page(0.9676)\n",
      "[0.01938918 0.02153973 0.02027559 0.02117664 0.02131801 0.01888767\n",
      " 0.02072306 0.96757201 0.01714621 0.02265629 0.02038331 0.0216113\n",
      " 0.02421197 0.01911032 0.02214437 0.01972708 0.02124715 0.02205081\n",
      " 0.02398501 0.02013235]\n",
      "1002_pred9, write on paper with pen(0.9785)\n",
      "[0.01785222 0.01942414 0.0193489  0.01935277 0.02145729 0.018267\n",
      " 0.02129361 0.02307435 0.01792861 0.97845299 0.01881613 0.02263092\n",
      " 0.02246855 0.0173793  0.02014712 0.0201418  0.02201951 0.01972143\n",
      " 0.02307163 0.02013588]\n",
      "1003_pred1, drink/eat for 2 minutes(0.3821)\n",
      "[0.02415963 0.02159324 0.02463597 0.02519948 0.06145393 0.02485105\n",
      " 0.02560196 0.02474936 0.02919511 0.02310249 0.02600589 0.02426511\n",
      " 0.03264389 0.19177436 0.38207977 0.02767196 0.02628027 0.02632443\n",
      " 0.02867367 0.02314129]\n",
      "1003_pred17, hand-eye coordination (tennis ball)(0.9702)\n",
      "[0.02484074 0.02249875 0.02339324 0.02298934 0.02554086 0.02344319\n",
      " 0.02222206 0.02444101 0.02280032 0.02309984 0.02344046 0.02595997\n",
      " 0.02531415 0.02243798 0.02515367 0.02428364 0.0254357  0.02507389\n",
      " 0.97019845 0.02384623]\n",
      "1003_pred9, exercise: sit up/stand down repeatedly(0.7531)\n",
      "[0.02384084 0.02683756 0.02721541 0.02445198 0.02994496 0.0297285\n",
      " 0.02665332 0.02821238 0.02762552 0.02573895 0.02993895 0.02717525\n",
      " 0.0260274  0.02728067 0.02631298 0.03066805 0.02788728 0.75307642\n",
      " 0.02977432 0.22846605]\n",
      "1003_pred6, make a telephone call(0.4377)\n",
      "[0.02955525 0.03177063 0.05788222 0.03007401 0.04599421 0.02887588\n",
      " 0.03017788 0.0299265  0.02870114 0.02729272 0.03259522 0.03530571\n",
      " 0.0357083  0.43765375 0.03491573 0.09081435 0.03330647 0.03207249\n",
      " 0.03767578 0.051276  ]\n",
      "1003_pred5, drink/eat for 2 minutes(0.9783)\n",
      "[0.02340858 0.02155473 0.02337645 0.02511452 0.02523397 0.02277303\n",
      " 0.02571786 0.02431614 0.02278585 0.02219998 0.02522091 0.02223284\n",
      " 0.02743205 0.0212423  0.97826005 0.02371427 0.02451078 0.02382403\n",
      " 0.02732962 0.02330253]\n",
      "1003_pred10, have conversation with experimenter in room(0.9705)\n",
      "[0.02174914 0.0225975  0.02526131 0.02298431 0.02479219 0.02222544\n",
      " 0.02330381 0.02595763 0.0220796  0.0246774  0.0227287  0.02689183\n",
      " 0.97045893 0.02468594 0.02666266 0.02400985 0.02207993 0.02388939\n",
      " 0.02728966 0.02120279]\n",
      "1003_pred4, write an email(0.9822)\n",
      "[0.98218486 0.02097429 0.02245864 0.02047701 0.02334375 0.02303431\n",
      " 0.02168757 0.02255847 0.0215355  0.02058326 0.02229743 0.02351247\n",
      " 0.02274556 0.01926527 0.02466793 0.02170798 0.02419987 0.02355744\n",
      " 0.02915203 0.02057647]\n",
      "1003_pred11, go to a news website and browse(0.9755)\n",
      "[0.02202444 0.02538077 0.02229739 0.02314177 0.02382444 0.02068294\n",
      " 0.02202537 0.02441148 0.01889323 0.02403146 0.023037   0.97553599\n",
      " 0.02663431 0.02014697 0.02123165 0.02353171 0.02323731 0.02334185\n",
      " 0.02842594 0.02181045]\n",
      "1003_pred18, watch a youtube video(0.9757)\n",
      "[0.02264267 0.02318421 0.02464711 0.02112131 0.02756579 0.02509193\n",
      " 0.02575468 0.02394604 0.02539958 0.02178981 0.97565262 0.02482649\n",
      " 0.0244883  0.02509838 0.02710546 0.02484972 0.02560047 0.02741574\n",
      " 0.02743167 0.02637328]\n",
      "1003_pred14, edit/create presentation(0.9776)\n",
      "[0.02152951 0.01885939 0.97757923 0.0211517  0.02336031 0.02162496\n",
      " 0.02247139 0.02209225 0.02114149 0.02053009 0.02220739 0.02210536\n",
      " 0.02398007 0.01977634 0.02173598 0.0208636  0.02503425 0.02260133\n",
      " 0.02489778 0.02038656]\n",
      "1003_pred16, read text/numbers on page(0.8319)\n",
      "[0.02294569 0.02693377 0.02450158 0.02770815 0.05553995 0.02296312\n",
      " 0.02678974 0.83190653 0.02099647 0.02843401 0.02482547 0.02750962\n",
      " 0.03077372 0.02337637 0.02663085 0.02447047 0.0255956  0.02691564\n",
      " 0.03050327 0.02317516]\n",
      "1003_pred13, clean e.g. sweaping the floor, wipe, ...(0.9475)\n",
      "[0.02542376 0.02271002 0.02778524 0.02286331 0.02860901 0.02385353\n",
      " 0.02578212 0.02498779 0.02339293 0.02432749 0.0260735  0.02582531\n",
      " 0.02333617 0.02426593 0.02716613 0.02634835 0.94752633 0.02483648\n",
      " 0.03378136 0.03170591]\n",
      "1003_pred19, pace the room(0.9712)\n",
      "[0.01985322 0.02207683 0.02102093 0.02085242 0.0241611  0.02292762\n",
      " 0.02067086 0.02272968 0.02173582 0.0213831  0.02456477 0.02257098\n",
      " 0.02198174 0.02161809 0.02339856 0.02520525 0.02380061 0.02649984\n",
      " 0.0250802  0.97121769]\n",
      "1003_pred2, put documents in order(0.7281)\n",
      "[0.03292048 0.02739578 0.03034409 0.02787321 0.0321418  0.03500017\n",
      " 0.72809387 0.02935878 0.06107871 0.02870932 0.03088133 0.02987892\n",
      " 0.03165461 0.02888993 0.03205386 0.03009874 0.03229223 0.03182447\n",
      " 0.0326139  0.0271584 ]\n",
      "1003_pred0, zone out and fixate(0.5290)\n",
      "[0.02788551 0.03341578 0.03120253 0.52896349 0.04594096 0.03197431\n",
      " 0.02970796 0.03459625 0.02961929 0.0293056  0.03048731 0.03655486\n",
      " 0.03865736 0.02805091 0.04229297 0.05653834 0.03236283 0.03131481\n",
      " 0.04581408 0.03078633]\n",
      "1003_pred7, arrange money in change jar(0.9791)\n",
      "[0.02059278 0.02039011 0.02251389 0.02300424 0.0216955  0.02026728\n",
      " 0.0196711  0.02049257 0.97913189 0.02012499 0.02420474 0.02043333\n",
      " 0.02328334 0.02158587 0.02301364 0.02476237 0.02234378 0.02510784\n",
      " 0.02581982 0.02145118]\n",
      "1003_pred3, write on paper with pen(0.9690)\n",
      "[0.01936431 0.02109636 0.02047919 0.02111852 0.02449704 0.02058617\n",
      " 0.02277292 0.02805667 0.01965958 0.96902514 0.0204846  0.02456516\n",
      " 0.02481549 0.01893303 0.02189632 0.02189278 0.02349898 0.02141659\n",
      " 0.02466535 0.02144871]\n",
      "1003_pred15, physical precision task(0.9412)\n",
      "[0.0303023  0.0251553  0.02604723 0.02497166 0.02669465 0.9411774\n",
      " 0.02423461 0.02368411 0.02761612 0.02179563 0.02674275 0.02472756\n",
      " 0.02628546 0.0240638  0.02894699 0.02635742 0.02593673 0.02851994\n",
      " 0.02925499 0.02473135]\n",
      "1003_pred12, read on screen(0.3414)\n",
      "[0.02700364 0.34143344 0.0322916  0.0655674  0.03359659 0.03000424\n",
      " 0.03024077 0.03178767 0.02993952 0.02838212 0.19081148 0.03450177\n",
      " 0.03286488 0.02919386 0.03142974 0.2147094  0.03050664 0.03139608\n",
      " 0.04139938 0.03408163]\n",
      "1003_pred8, go to a news website and browse(0.9429)\n",
      "[0.02442769 0.05099678 0.02591406 0.02641277 0.02698073 0.02376437\n",
      " 0.0248941  0.02836208 0.02202844 0.02704725 0.0292895  0.94285491\n",
      " 0.02978133 0.02314049 0.02443161 0.02707245 0.02609814 0.02681386\n",
      " 0.03315984 0.02505927]\n",
      "1004_pred11, read text/numbers on page(0.9471)\n",
      "[0.02103035 0.0237505  0.02242076 0.02738598 0.02660815 0.02080115\n",
      " 0.02280912 0.94706425 0.0189107  0.02564695 0.02220272 0.02491165\n",
      " 0.02635526 0.0208646  0.02434184 0.02248303 0.02360374 0.02390831\n",
      " 0.02681229 0.02176653]\n",
      "1004_pred15, close eyes and sit still(0.4561)\n",
      "[0.02525033 0.0672721  0.02722344 0.23898826 0.03073651 0.02680709\n",
      " 0.02560902 0.03168772 0.02693623 0.02482532 0.02676366 0.03299884\n",
      " 0.02751153 0.02507633 0.02750068 0.45608857 0.02918026 0.03004991\n",
      " 0.03542518 0.02778505]\n",
      "1004_pred10, use a calculator to add up numbers on sheet(0.7772)\n",
      "[0.02285304 0.02596685 0.02510528 0.02885175 0.77723239 0.02230252\n",
      " 0.02683343 0.13409511 0.0223055  0.02771214 0.02637488 0.02661925\n",
      " 0.02713806 0.02336328 0.02512704 0.02509758 0.02799816 0.02706076\n",
      " 0.02952249 0.02457867]\n",
      "1004_pred2, make a telephone call(0.3604)\n",
      "[0.03206    0.02834567 0.02931933 0.02929245 0.25908015 0.02585325\n",
      " 0.02843896 0.02798126 0.02836033 0.02543294 0.02999859 0.03318497\n",
      " 0.03422642 0.36040928 0.0578476  0.03256349 0.03073437 0.0303399\n",
      " 0.03373575 0.02847752]\n",
      "1004_pred13, exercise: sit up/stand down repeatedly(0.9768)\n",
      "[0.02168274 0.02157141 0.02392856 0.02143187 0.02653158 0.025915\n",
      " 0.02341113 0.02443338 0.02406649 0.02170799 0.02536418 0.02380614\n",
      " 0.02303032 0.02241504 0.023075   0.02498532 0.02313991 0.97677983\n",
      " 0.02537803 0.02333103]\n",
      "1004_pred5, arrange money in change jar(0.9805)\n",
      "[0.01979518 0.01973507 0.02198181 0.0221309  0.02092398 0.01910047\n",
      " 0.01850937 0.01978693 0.98048892 0.01931418 0.02355296 0.01971985\n",
      " 0.02240022 0.02089695 0.02192173 0.02405105 0.02145833 0.02432753\n",
      " 0.02472561 0.02071528]\n",
      "1004_pred8, write on paper with pen(0.9638)\n",
      "[0.02031529 0.02120087 0.02069014 0.02113817 0.02557478 0.02218381\n",
      " 0.02302552 0.02655679 0.01984285 0.96375333 0.02054887 0.02467176\n",
      " 0.02505394 0.01898422 0.02178983 0.02192131 0.02349947 0.02152512\n",
      " 0.02500122 0.02150636]\n",
      "1004_pred9, hand-eye coordination (tennis ball)(0.9583)\n",
      "[0.02778871 0.02575282 0.02663843 0.02723162 0.02887491 0.02660741\n",
      " 0.02631686 0.02934989 0.02576396 0.02644241 0.02660079 0.02944854\n",
      " 0.03131258 0.02566789 0.02904085 0.0270955  0.02801678 0.02751078\n",
      " 0.95834818 0.02653538]\n",
      "1004_pred19, go to a news website and browse(0.7143)\n",
      "[0.02411128 0.23225263 0.02788619 0.02575297 0.02656784 0.02412829\n",
      " 0.02426446 0.02716679 0.02169834 0.0263352  0.03077143 0.71430916\n",
      " 0.02884711 0.02289638 0.02338508 0.02730844 0.02549016 0.02654576\n",
      " 0.03124241 0.02493019]\n",
      "1004_pred1, read text/numbers on page(0.4032)\n",
      "[0.0212405  0.02485706 0.02302336 0.1988124  0.11344534 0.02047081\n",
      " 0.02314597 0.4032455  0.02079401 0.02644925 0.02415183 0.02551355\n",
      " 0.02553357 0.02166063 0.02425478 0.03633292 0.02460418 0.02516636\n",
      " 0.02865848 0.0233618 ]\n",
      "1004_pred6, edit/create presentation(0.9797)\n",
      "[0.02039359 0.01867516 0.97973932 0.02060049 0.02289575 0.02120539\n",
      " 0.02204527 0.0216569  0.02069411 0.01996146 0.02200584 0.02127298\n",
      " 0.02352069 0.01979438 0.02143311 0.02042356 0.02445746 0.02229869\n",
      " 0.02434282 0.02004784]\n",
      "1004_pred0, write an email(0.9799)\n",
      "[0.97991215 0.02126407 0.02414149 0.02051746 0.02375171 0.02274581\n",
      " 0.02138117 0.02273037 0.02123059 0.02101038 0.02245671 0.02405425\n",
      " 0.02280572 0.01929262 0.02468448 0.02177985 0.0246311  0.02360675\n",
      " 0.02929019 0.02090599]\n",
      "1004_pred12, pace the room(0.9580)\n",
      "[0.0194704  0.02156018 0.02047336 0.0205791  0.02337117 0.02262148\n",
      " 0.02045119 0.02237264 0.02151535 0.02083047 0.02425223 0.02200881\n",
      " 0.0215414  0.02049806 0.02268215 0.02481345 0.02300175 0.03759372\n",
      " 0.0245307  0.95798772]\n",
      "1004_pred14, watch a youtube video(0.9799)\n",
      "[0.02078241 0.02040719 0.02226922 0.01893483 0.02518014 0.02287036\n",
      " 0.02352121 0.02174667 0.02346499 0.01987325 0.97990494 0.02203634\n",
      " 0.02225821 0.02291114 0.02497255 0.02259133 0.02360499 0.02477959\n",
      " 0.02488858 0.02401544]\n",
      "1004_pred18, make a telephone call(0.3803)\n",
      "[0.02819513 0.02244538 0.32770137 0.02460945 0.02861448 0.0248821\n",
      " 0.02642584 0.02525541 0.02726077 0.0261019  0.02710163 0.03101407\n",
      " 0.02848573 0.38029537 0.02589201 0.02634727 0.03185396 0.02676805\n",
      " 0.02947748 0.02410292]\n",
      "1004_pred4, put documents in order(0.7098)\n",
      "[0.02516557 0.0239312  0.02655112 0.02331494 0.0280396  0.04232499\n",
      " 0.70983636 0.02525876 0.02238179 0.02542631 0.0266383  0.02571338\n",
      " 0.02588994 0.02413546 0.02800816 0.02555753 0.1728949  0.02652687\n",
      " 0.02999825 0.0244946 ]\n",
      "1004_pred16, clean e.g. sweaping the floor, wipe, ...(0.8698)\n",
      "[0.0263639  0.02487657 0.02815109 0.02466764 0.03030491 0.02544552\n",
      " 0.03705366 0.02730915 0.02597911 0.0261187  0.02822265 0.02800593\n",
      " 0.02581743 0.02575876 0.02724468 0.02792419 0.86977028 0.03105034\n",
      " 0.03953321 0.06031834]\n",
      "1004_pred7, have conversation with experimenter in room(0.9721)\n",
      "[0.02120663 0.02183943 0.02401244 0.02225391 0.02377314 0.02115633\n",
      " 0.02226588 0.02521167 0.02091859 0.02392123 0.02194335 0.02575161\n",
      " 0.97207652 0.02355497 0.02336406 0.02298934 0.0209152  0.0222312\n",
      " 0.0257189  0.01990043]\n",
      "1004_pred17, physical precision task(0.9699)\n",
      "[0.02374033 0.02378805 0.02448011 0.02336998 0.0246698  0.96986054\n",
      " 0.02262819 0.0221547  0.02085011 0.02093266 0.02456799 0.02281846\n",
      " 0.02364478 0.02205556 0.02469503 0.02415241 0.02425943 0.0266739\n",
      " 0.02825306 0.02368858]\n",
      "1004_pred3, go to a news website and browse(0.9768)\n",
      "[0.02089356 0.02505167 0.02082498 0.02243242 0.02329196 0.0201766\n",
      " 0.02126618 0.02474675 0.01819278 0.02334625 0.02200686 0.97675729\n",
      " 0.02562768 0.01964927 0.02036584 0.02250036 0.02252241 0.02264614\n",
      " 0.02737836 0.02113498]\n",
      "1005_pred10, exercise: sit up/stand down repeatedly(0.9713)\n",
      "[0.02347227 0.02403487 0.02577933 0.02329536 0.0290581  0.02783504\n",
      " 0.02556105 0.02664475 0.02634696 0.02363372 0.02808183 0.02609096\n",
      " 0.02568611 0.02495855 0.02548902 0.02721139 0.02526973 0.97131687\n",
      " 0.02876149 0.02569283]\n",
      "1005_pred19, arrange money in change jar(0.9754)\n",
      "[0.0216917  0.0198262  0.0221146  0.02268502 0.02104829 0.02215853\n",
      " 0.01989094 0.01947049 0.97538291 0.01987027 0.02395737 0.01993667\n",
      " 0.02273653 0.02135217 0.02290272 0.02444768 0.02183114 0.02491503\n",
      " 0.02510243 0.02120578]\n",
      "1005_pred11, go to a news website and browse(0.9762)\n",
      "[0.02220662 0.02387157 0.02248982 0.02250179 0.02374439 0.02018361\n",
      " 0.02193039 0.02348809 0.01869805 0.02385248 0.02302742 0.97621085\n",
      " 0.02620415 0.02019263 0.02073472 0.02284981 0.02304733 0.0230141\n",
      " 0.02743149 0.02126492]\n",
      "1005_pred12, clean e.g. sweaping the floor, wipe, ...(0.9793)\n",
      "[0.02128537 0.01953638 0.02419787 0.01949259 0.02539846 0.02066932\n",
      " 0.02001548 0.02191477 0.02011502 0.02216585 0.0224501  0.02208027\n",
      " 0.01998649 0.02016239 0.02235069 0.022501   0.97925123 0.02163655\n",
      " 0.02435317 0.02295154]\n",
      "1005_pred3, zone out and fixate(0.9748)\n",
      "[0.01952295 0.02185797 0.02177415 0.97479037 0.02604628 0.02202486\n",
      " 0.01990835 0.02277154 0.02195986 0.02072087 0.019661   0.02306554\n",
      " 0.02279844 0.01964024 0.02461231 0.02310511 0.02161534 0.02118531\n",
      " 0.02555918 0.02089347]\n",
      "1005_pred15, put documents in order(0.7783)\n",
      "[0.08467481 0.0265871  0.02847702 0.02430331 0.03174218 0.0484534\n",
      " 0.77829066 0.02816745 0.02459162 0.02907    0.02782279 0.0296457\n",
      " 0.02890521 0.0260396  0.02959127 0.02757676 0.0320702  0.02990877\n",
      " 0.02982592 0.02520105]\n",
      "1005_pred2, watch a youtube video(0.7131)\n",
      "[0.02674518 0.03522498 0.03033724 0.02578127 0.0315287  0.02930985\n",
      " 0.02924106 0.02848268 0.02796612 0.02643917 0.71306731 0.06119937\n",
      " 0.02929976 0.02744438 0.02845766 0.02901005 0.02894085 0.03186899\n",
      " 0.03218521 0.02927703]\n",
      "1005_pred1, read on screen(0.4432)\n",
      "[0.02405668 0.44316281 0.06268534 0.02200073 0.0250782  0.0247864\n",
      " 0.02353137 0.02329469 0.02094025 0.02301614 0.02810706 0.13565356\n",
      " 0.02471137 0.0219443  0.02302663 0.02707603 0.02495524 0.0223423\n",
      " 0.02921239 0.02305889]\n",
      "1005_pred5, physical precision task(0.9693)\n",
      "[0.02363789 0.02359332 0.02449719 0.02338149 0.02440331 0.96929346\n",
      " 0.02236402 0.02221464 0.02068447 0.02159944 0.02425889 0.02278948\n",
      " 0.02381979 0.02204718 0.02459496 0.02380066 0.02417915 0.02652033\n",
      " 0.02773883 0.02350288]\n",
      "1005_pred4, close eyes and sit still(0.2885)\n",
      "[0.02539961 0.08363161 0.02703025 0.22225933 0.03031202 0.02727817\n",
      " 0.02710776 0.05428321 0.02707684 0.02769931 0.05205487 0.03474544\n",
      " 0.02997577 0.02548815 0.0290384  0.28846626 0.02908475 0.0293124\n",
      " 0.03603675 0.02699648]\n",
      "1005_pred16, pace the room(0.8374)\n",
      "[0.0207122  0.02291762 0.02224145 0.02188762 0.02456819 0.02406385\n",
      " 0.02186649 0.02403428 0.0228719  0.02175068 0.02618606 0.02346648\n",
      " 0.02264841 0.02217257 0.02376091 0.02603947 0.02476065 0.14490146\n",
      " 0.02676504 0.83744418]\n",
      "1005_pred13, hand-eye coordination (tennis ball)(0.9754)\n",
      "[0.02387015 0.02175577 0.02234507 0.02252332 0.02435808 0.02251727\n",
      " 0.02121904 0.02422919 0.02163704 0.02229475 0.02205766 0.02532471\n",
      " 0.02508932 0.02128985 0.02368263 0.02255984 0.02223363 0.02292281\n",
      " 0.97539472 0.02183777]\n",
      "1005_pred6, edit/create presentation(0.9804)\n",
      "[0.01966882 0.01797405 0.98040175 0.02010958 0.0221849  0.02070769\n",
      " 0.02137046 0.02111746 0.02005579 0.01932691 0.02121795 0.02041403\n",
      " 0.02276019 0.01903932 0.02082998 0.01981076 0.0237517  0.02161713\n",
      " 0.02367174 0.01948305]\n",
      "1005_pred0, go to a news website and browse(0.5337)\n",
      "[0.02247796 0.23500542 0.02765089 0.02472478 0.02620205 0.02372041\n",
      " 0.02411671 0.02602442 0.02237018 0.02578374 0.0529904  0.5336836\n",
      " 0.02746849 0.0227442  0.02348563 0.0250669  0.02433976 0.02537912\n",
      " 0.03018128 0.02460402]\n",
      "1005_pred7, use a calculator to add up numbers on sheet(0.9563)\n",
      "[0.02210722 0.02410226 0.02501944 0.02661684 0.95632931 0.02332621\n",
      " 0.02578037 0.02459563 0.02099848 0.02417118 0.02533068 0.02480447\n",
      " 0.02560654 0.02240189 0.02437196 0.02398312 0.02759507 0.02655085\n",
      " 0.02845565 0.02403236]\n",
      "1005_pred18, make a telephone call(0.7366)\n",
      "[0.02391724 0.02822814 0.02756011 0.02681939 0.03015005 0.02622553\n",
      " 0.02914913 0.02867496 0.02772658 0.02442517 0.11565925 0.0284973\n",
      " 0.03378483 0.73662353 0.08287892 0.03028484 0.02846246 0.0309736\n",
      " 0.03335322 0.02763006]\n",
      "1005_pred14, pace the room(0.3080)\n",
      "[0.02536763 0.02523488 0.02901273 0.02682466 0.03203799 0.02816664\n",
      " 0.02760505 0.02890116 0.02776422 0.02633763 0.03218325 0.02847229\n",
      " 0.02935201 0.20512883 0.04398395 0.03942411 0.03944891 0.06428486\n",
      " 0.03533624 0.30800135]\n",
      "1005_pred17, drink/eat for 2 minutes(0.9676)\n",
      "[0.02437273 0.0221457  0.02438642 0.02567276 0.02647158 0.02402717\n",
      " 0.02685205 0.02619614 0.02446738 0.02294486 0.02645795 0.02344647\n",
      " 0.02829376 0.03347301 0.96759589 0.02553205 0.02544379 0.02490203\n",
      " 0.02917103 0.02498751]\n",
      "1005_pred9, write on paper with pen(0.8640)\n",
      "[0.02024978 0.02141781 0.02154422 0.0205439  0.02357657 0.04788948\n",
      " 0.02305832 0.02450008 0.01913559 0.86399552 0.02044722 0.02409761\n",
      " 0.02371724 0.01890875 0.0210652  0.02150277 0.02458003 0.02168696\n",
      " 0.02479744 0.02150421]\n",
      "1005_pred8, close eyes and sit still(0.4603)\n",
      "[0.02563471 0.04021369 0.02638119 0.05128349 0.03071072 0.02645311\n",
      " 0.02707325 0.02747739 0.02746011 0.02512055 0.2396891  0.03173645\n",
      " 0.02764786 0.02657917 0.02805921 0.46031929 0.02846516 0.02965019\n",
      " 0.03478847 0.02734585]\n",
      "1006_pred7, write on paper with pen(0.6997)\n",
      "[0.02543189 0.02489265 0.02563914 0.02525259 0.22188043 0.03114097\n",
      " 0.02631261 0.02886594 0.02278363 0.69967227 0.02461578 0.02785075\n",
      " 0.0282444  0.02218919 0.02444049 0.02529836 0.02792792 0.02600614\n",
      " 0.02930043 0.0260699 ]\n",
      "1006_pred18, close eyes and sit still(0.4643)\n",
      "[0.0263912  0.02982981 0.02802516 0.14931133 0.03151275 0.03006235\n",
      " 0.02842549 0.02781324 0.02957017 0.02639072 0.08084384 0.0302167\n",
      " 0.03237031 0.02734889 0.03389361 0.4642779  0.02971758 0.03692136\n",
      " 0.03719149 0.0325573 ]\n",
      "1006_pred8, drink/eat for 2 minutes(0.8754)\n",
      "[0.02546771 0.02351404 0.0245304  0.02563335 0.02773978 0.0238309\n",
      " 0.02638154 0.02519423 0.02446723 0.02359924 0.02701542 0.02493385\n",
      " 0.02704631 0.03273346 0.8754136  0.04091833 0.02625094 0.02552359\n",
      " 0.02941837 0.02417387]\n",
      "1006_pred19, physical precision task(0.9662)\n",
      "[0.02429196 0.02440102 0.02475273 0.02358299 0.02545389 0.96615155\n",
      " 0.02367704 0.02308278 0.02046525 0.02287458 0.02456918 0.02313779\n",
      " 0.02371886 0.02238946 0.02454754 0.0239763  0.02517527 0.02717279\n",
      " 0.0285496  0.02396402]\n",
      "1006_pred9, arrange money in change jar(0.8234)\n",
      "[0.0252525  0.0237514  0.02626499 0.02531627 0.02463558 0.02602138\n",
      " 0.0668243  0.02406561 0.82337368 0.02382326 0.02726272 0.0240921\n",
      " 0.02674866 0.0250144  0.02611156 0.0275411  0.02675059 0.02913002\n",
      " 0.0315849  0.02464926]\n",
      "1006_pred4, have conversation with experimenter in room(0.5545)\n",
      "[0.02586127 0.02601979 0.02903771 0.02942414 0.03126541 0.02659836\n",
      " 0.02895328 0.02924598 0.02750368 0.0272669  0.02757983 0.02911068\n",
      " 0.55450829 0.02916705 0.2967854  0.03097373 0.02762033 0.02836128\n",
      " 0.03494867 0.02578209]\n",
      "1006_pred15, drink/eat for 2 minutes(0.7480)\n",
      "[0.02832648 0.02587762 0.02935204 0.0294909  0.03221091 0.0280747\n",
      " 0.03091284 0.02999003 0.02984157 0.02661623 0.03131331 0.02887413\n",
      " 0.03449944 0.11592286 0.74802546 0.03322407 0.02986436 0.03100142\n",
      " 0.03544917 0.03160332]\n",
      "1006_pred16, exercise: sit up/stand down repeatedly(0.9733)\n",
      "[0.02271634 0.02350284 0.02547258 0.02312011 0.02816086 0.02742679\n",
      " 0.02496298 0.02636995 0.02573407 0.02295383 0.02774527 0.02524238\n",
      " 0.02522346 0.02410739 0.02470781 0.02649801 0.02463047 0.97331086\n",
      " 0.02777954 0.0250106 ]\n",
      "1006_pred11, read on screen(0.9550)\n",
      "[0.02058456 0.95497271 0.02066646 0.02225787 0.02494747 0.02243223\n",
      " 0.02209041 0.0241581  0.02027294 0.02213001 0.02422155 0.03961466\n",
      " 0.02391956 0.0204917  0.02176345 0.02207814 0.021671   0.02286852\n",
      " 0.02566417 0.02277322]\n",
      "1006_pred17, pace the room(0.9170)\n",
      "[0.02402724 0.02544398 0.02578477 0.0236592  0.02850033 0.02618995\n",
      " 0.02521232 0.02670946 0.02542215 0.0247584  0.02902119 0.02638344\n",
      " 0.02548749 0.02600548 0.02675795 0.03065171 0.03677632 0.03501224\n",
      " 0.037166   0.91702691]\n",
      "1006_pred10, edit/create presentation(0.9801)\n",
      "[0.02016972 0.01850687 0.98007563 0.02046493 0.02263874 0.02104612\n",
      " 0.02175383 0.02147826 0.02052446 0.01978046 0.02157179 0.02095953\n",
      " 0.02320793 0.01916244 0.02111738 0.02006372 0.02424039 0.02197159\n",
      " 0.0241178  0.01989688]\n",
      "1006_pred14, use a calculator to add up numbers on sheet(0.8869)\n",
      "[0.02278242 0.02481027 0.02580679 0.02794634 0.88694539 0.02478909\n",
      " 0.0262249  0.0256197  0.02116753 0.02569056 0.02587404 0.0266671\n",
      " 0.02664528 0.0232296  0.02519888 0.02573271 0.02763369 0.02732303\n",
      " 0.02879917 0.02472884]\n",
      "1006_pred2, drink/eat for 2 minutes(0.5124)\n",
      "[0.02504599 0.02333943 0.02501323 0.02602603 0.02884078 0.0264927\n",
      " 0.02881653 0.02708707 0.02595077 0.02390325 0.02816972 0.02534102\n",
      " 0.02985301 0.47274798 0.51244035 0.0278587  0.02815469 0.02784402\n",
      " 0.03127807 0.02624438]\n",
      "1006_pred6, go to a news website and browse(0.5577)\n",
      "[0.0248359  0.19025025 0.03389345 0.02617926 0.02843807 0.02588461\n",
      " 0.02665642 0.02806951 0.02410084 0.02721292 0.0430884  0.55771154\n",
      " 0.02975044 0.02480502 0.02597242 0.02705529 0.02607027 0.0276682\n",
      " 0.03271298 0.02620787]\n",
      "1006_pred1, hand-eye coordination (tennis ball)(0.9666)\n",
      "[0.02085171 0.0188357  0.01913156 0.01841942 0.02106238 0.0189482\n",
      " 0.01885402 0.02017965 0.0195709  0.0196958  0.01910896 0.02215887\n",
      " 0.02086996 0.0185418  0.020199   0.01930679 0.02328636 0.0208408\n",
      " 0.96657471 0.01984376]\n",
      "1006_pred5, put documents in order(0.9712)\n",
      "[0.02093365 0.02227563 0.02356542 0.02047868 0.02611204 0.02229401\n",
      " 0.97122201 0.02339618 0.01843001 0.02371089 0.02410817 0.0235621\n",
      " 0.02413147 0.02276526 0.02559199 0.02306586 0.02462666 0.02410647\n",
      " 0.02542439 0.02147151]\n",
      "1006_pred13, write an email(0.7524)\n",
      "[0.75236143 0.02740181 0.18169646 0.02415085 0.02742151 0.02464146\n",
      " 0.02720544 0.02490831 0.02332821 0.02399188 0.02595512 0.08081983\n",
      " 0.02548868 0.02159158 0.02691264 0.02397852 0.02871408 0.02674398\n",
      " 0.03214752 0.0234802 ]\n",
      "1006_pred12, clean e.g. sweaping the floor, wipe, ...(0.9778)\n",
      "[0.02245466 0.02021137 0.02481446 0.02022874 0.02616136 0.02133402\n",
      " 0.02173157 0.02257958 0.02073237 0.02291334 0.02315046 0.02311028\n",
      " 0.02079986 0.02089165 0.02310115 0.02309898 0.97779971 0.02246557\n",
      " 0.02571762 0.02230694]\n",
      "1006_pred0, drink/eat for 2 minutes(0.4060)\n",
      "[0.02676442 0.02751852 0.02793848 0.030271   0.04073583 0.02596593\n",
      " 0.02861406 0.18455994 0.02563514 0.0274832  0.02931888 0.02887069\n",
      " 0.06219815 0.02791058 0.40603802 0.08688307 0.03015725 0.02890257\n",
      " 0.06047403 0.02557768]\n",
      "1006_pred3, watch a youtube video(0.9791)\n",
      "[0.02108894 0.02156226 0.02267056 0.01929641 0.02564645 0.02335927\n",
      " 0.02392511 0.02216502 0.02371065 0.02015604 0.97912546 0.02248543\n",
      " 0.02263151 0.0234166  0.02540176 0.02275528 0.02384234 0.02530056\n",
      " 0.02530931 0.02457094]\n",
      "1007_pred0, read on screen(0.6868)\n",
      "[0.0224031  0.68678298 0.03704609 0.02388076 0.0273382  0.02458641\n",
      " 0.0242365  0.026677   0.02301886 0.02505874 0.03146416 0.2472467\n",
      " 0.02711739 0.02249793 0.02400655 0.02458545 0.02392292 0.02472384\n",
      " 0.02897397 0.02458518]\n",
      "1007_pred16, pace the room(0.8170)\n",
      "[0.02481665 0.02628327 0.02863615 0.02419037 0.03088677 0.02716388\n",
      " 0.02626303 0.02760989 0.02627426 0.02698569 0.02970165 0.02808761\n",
      " 0.02700628 0.04042537 0.02922992 0.03003207 0.05867075 0.03099789\n",
      " 0.03223977 0.81698914]\n",
      "1007_pred18, clean e.g. sweaping the floor, wipe, ...(0.5867)\n",
      "[0.02783112 0.02709985 0.03195018 0.02588326 0.03416284 0.02756127\n",
      " 0.02749389 0.02932758 0.02682108 0.02885207 0.03095789 0.03036602\n",
      " 0.02785942 0.03447362 0.03802305 0.03356777 0.58666514 0.02999108\n",
      " 0.04334848 0.16693589]\n",
      "1007_pred6, read text/numbers on page(0.9615)\n",
      "[0.01973479 0.02210734 0.02080532 0.02176038 0.02297926 0.01951847\n",
      " 0.02154812 0.96146865 0.01748916 0.02459023 0.02072151 0.02243611\n",
      " 0.02457231 0.01945484 0.02273173 0.0202036  0.02174443 0.02224429\n",
      " 0.02430013 0.02039304]\n",
      "1007_pred17, hand-eye coordination (tennis ball)(0.9638)\n",
      "[0.02559465 0.02416347 0.02402877 0.02424448 0.0266673  0.02419453\n",
      " 0.02298473 0.0249456  0.02351558 0.02399618 0.02455047 0.02651185\n",
      " 0.02577048 0.02306753 0.02582903 0.02570839 0.02783593 0.02714747\n",
      " 0.96375713 0.02580556]\n",
      "1007_pred3, close eyes and sit still(0.3583)\n",
      "[0.02659707 0.03253358 0.02784386 0.26287923 0.04027253 0.02930765\n",
      " 0.02779053 0.08678638 0.02690219 0.02874817 0.02900014 0.03305738\n",
      " 0.03124545 0.02719525 0.02931061 0.35829828 0.03090014 0.03102878\n",
      " 0.04484403 0.02841225]\n",
      "1007_pred19, drink/eat for 2 minutes(0.9785)\n",
      "[0.02291555 0.02114798 0.02296993 0.02457164 0.02460699 0.02234978\n",
      " 0.02541894 0.02410987 0.02255425 0.02177025 0.02492286 0.02189071\n",
      " 0.0262626  0.02173008 0.97851185 0.02339573 0.02416417 0.0233954\n",
      " 0.02703166 0.02275659]\n",
      "1007_pred14, close eyes and sit still(0.9779)\n",
      "[0.02034647 0.02109394 0.02103345 0.02225336 0.02401679 0.02133027\n",
      " 0.02132975 0.02141952 0.02255977 0.0210873  0.0222587  0.02280097\n",
      " 0.02254824 0.02083633 0.02277323 0.97789146 0.02400988 0.02397371\n",
      " 0.02527378 0.02427366]\n",
      "1007_pred5, edit/create presentation(0.5212)\n",
      "[0.3350526  0.02715562 0.52122765 0.0266382  0.03064322 0.02677215\n",
      " 0.02648162 0.02734194 0.02698335 0.02646651 0.02815768 0.03285184\n",
      " 0.02817676 0.02482569 0.02940162 0.02710398 0.03679757 0.02816232\n",
      " 0.03481239 0.02651066]\n",
      "1007_pred1, write on paper with pen(0.3749)\n",
      "[0.11740035 0.02540793 0.09928876 0.02228579 0.0318807  0.02882859\n",
      " 0.02414812 0.02455304 0.02038705 0.37489291 0.02349522 0.02840958\n",
      " 0.02618393 0.02024328 0.02317817 0.0236011  0.03028751 0.02423558\n",
      " 0.02802981 0.02320201]\n",
      "1007_pred12, use a calculator to add up numbers on sheet(0.8158)\n",
      "[0.03059308 0.02658716 0.02919487 0.02892887 0.81579683 0.03698286\n",
      " 0.02875434 0.02763476 0.02464704 0.03419001 0.02923209 0.02834767\n",
      " 0.02963665 0.02580415 0.03087066 0.02819063 0.03082246 0.03086447\n",
      " 0.03220718 0.02804737]\n",
      "1007_pred4, put documents in order(0.9456)\n",
      "[0.02220395 0.02470071 0.0247766  0.02254822 0.02775729 0.02372317\n",
      " 0.94559666 0.02643702 0.02211447 0.02507255 0.02588751 0.02606849\n",
      " 0.02803161 0.02406554 0.02690986 0.02444852 0.02455655 0.02611384\n",
      " 0.03026073 0.02261182]\n",
      "1007_pred2, watch a youtube video(0.9082)\n",
      "[0.02387553 0.0233007  0.02741606 0.02186385 0.02955203 0.02513454\n",
      " 0.02670499 0.02459888 0.0266549  0.02297439 0.90822001 0.02694958\n",
      " 0.02682871 0.06022186 0.02843437 0.02805004 0.02680529 0.02881189\n",
      " 0.02954174 0.02753719]\n",
      "1007_pred7, arrange money in change jar(0.9769)\n",
      "[0.0214513  0.02053516 0.02292752 0.02340392 0.02154782 0.02137253\n",
      " 0.01795782 0.02069784 0.97691965 0.01996122 0.02435025 0.02130777\n",
      " 0.02347591 0.02116757 0.02325015 0.02486376 0.02225103 0.02480073\n",
      " 0.02516764 0.02124883]\n",
      "1007_pred11, have conversation with experimenter in room(0.9711)\n",
      "[0.02160659 0.02248058 0.02495304 0.02294874 0.02455389 0.02205378\n",
      " 0.02311907 0.0262125  0.02141496 0.02471322 0.02251178 0.02670639\n",
      " 0.97113299 0.02438957 0.02449295 0.02346642 0.02159009 0.02399256\n",
      " 0.02667221 0.02068947]\n",
      "1007_pred10, write on paper with pen(0.9778)\n",
      "[0.01791474 0.01947458 0.01925438 0.01936068 0.02158888 0.01838678\n",
      " 0.02133937 0.02365153 0.01802682 0.97784476 0.01902563 0.02277029\n",
      " 0.02278925 0.01750461 0.02028151 0.02023166 0.02216401 0.01981577\n",
      " 0.02319553 0.02019024]\n",
      "1007_pred8, exercise: sit up/stand down repeatedly(0.9774)\n",
      "[0.02160114 0.02145565 0.02358783 0.02122174 0.02626309 0.0254853\n",
      " 0.02327174 0.02419911 0.02365287 0.02149691 0.02542989 0.02342686\n",
      " 0.02275128 0.02209535 0.02290154 0.02476427 0.02285788 0.97738058\n",
      " 0.02499907 0.02192782]\n",
      "1007_pred9, read on screen(0.9702)\n",
      "[0.01994464 0.97021888 0.02044792 0.02157563 0.02413659 0.02198639\n",
      " 0.02148325 0.0233152  0.01958664 0.02151159 0.022113   0.02780774\n",
      " 0.02298716 0.01962557 0.02110184 0.02159846 0.02116075 0.02191053\n",
      " 0.02479668 0.02236631]\n",
      "1007_pred15, physical precision task(0.8351)\n",
      "[0.02700785 0.02576068 0.02703289 0.02582366 0.02595509 0.83513217\n",
      " 0.02640061 0.02453511 0.07220291 0.02231586 0.02748681 0.02489896\n",
      " 0.02719712 0.02447418 0.02786954 0.02730469 0.02647552 0.03008928\n",
      " 0.03050106 0.02543421]\n",
      "1007_pred13, make a telephone call(0.3887)\n",
      "[0.02789475 0.02979352 0.0345053  0.02821354 0.03554207 0.03051017\n",
      " 0.03030971 0.03130319 0.02944894 0.02954743 0.03543871 0.03173127\n",
      " 0.03484452 0.38874221 0.03819853 0.03720117 0.04047971 0.0426185\n",
      " 0.03954213 0.1441735 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (example, key) in tqdm(enumerate(zip(test_instances, autographer_feat_test.keys()))):\n",
    "    scores = results[i]\n",
    "    pred = np.argmax(results[i]) + 1\n",
    "    print(f\"{key}, {acts[pred]}({scores[pred - 1]:.4f})\")\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(results, \"results.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
